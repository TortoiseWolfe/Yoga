{
  "posts": [
    {
      "id": "post_sec_encrypt_01",
      "slug": "message-encryption-security-explained",
      "title": "How We Protect Your Messages: E2E Encryption",
      "content": "\n# How ScriptHammer Protects Your Messages\n\n## The Bottom Line\n\nYour messages on ScriptHammer are **end-to-end encrypted**. This means we literally cannot read them‚Äîonly you and the person you're messaging can. Even if someone broke into our servers, your message content would be scrambled nonsense to them.\n\n## Why We Built This\n\nMost social networks can read your private messages. Not because they're nosy (hopefully), but because of how they're built. Your messages sit on their servers in readable form, protected only by company policies and employee access controls.\n\nWe wanted something different. We believe private conversations should actually be private‚Äînot just from hackers, but from us too. Learn more about our [authentication system](/blog/authentication-supabase-oauth) that works alongside this encryption.\n\n## How It Works (The Simple Version)\n\nImagine you have a special lockbox:\n\n1. **Your password creates your unique key** - When you set up messaging, your password transforms into a digital key that only you have. We never see this key.\n\n2. **Every message gets locked before sending** - Before your message leaves your device, it gets scrambled using your key and the recipient's key together.\n\n3. **Only the recipient can unlock it** - The scrambled message travels through our servers to the other person. They use their key to unscramble it.\n\n4. **We only see scrambled text** - Our servers store your messages, but they're just random-looking characters to us. We couldn't read them even if we wanted to.\n\n## How We Compare to Other Platforms\n\n![Platform comparison chart showing ScriptHammer vs Facebook, Instagram, Twitter, and WhatsApp - only ScriptHammer and WhatsApp use encryption](/blog-images/message-encryption-security-explained/comparison-chart.png)\n\nWhatsApp also uses encryption, but there's a key difference: they control the key generation process. With ScriptHammer, your keys come from your password on your device‚Äîwe're never involved in creating them.\n\n## What We're Honest About\n\nNo security system is perfect, and we believe you deserve to know our limitations:\n\n### We protect your message content, not everything\n\n- **Protected**: The actual words you write\n- **Not protected**: Who you message and when (we need this to deliver messages)\n\nThink of it like the postal service: they can see you sent a letter to someone, but they can't read what's inside.\n\n### Your password is crucial\n\nIf you forget your messaging password, we cannot recover your old messages. This is actually a security feature‚Äîit means we truly don't have access‚Äîbut it also means **write down your password somewhere safe**.\n\n### We haven't had a professional security audit yet\n\nWe built this using industry-standard techniques recommended by [OWASP](https://cheatsheetseries.owasp.org/cheatsheets/Password%5FStorage%5FCheat%5FSheet.html) (the same math that protects banking websites), but we're a small team and haven't paid for a formal security audit. We're transparent about this.\n\n### One password, all messages\n\nIf someone gets your password, they could read all your messages (not just new ones). Some messaging apps like [Signal](https://signal.org/) rotate keys constantly to prevent this, but it would mean you couldn't access messages from a new device. We chose convenience here‚Äîbut it's a tradeoff you should understand.\n\n## Your Questions Answered\n\n**Q: What happens if you get hacked?**\nA: Hackers would get scrambled data. Without your password (which we don't have), they can't unscramble it.\n\n**Q: Can you read my messages if law enforcement asks?**\nA: No. We literally don't have the ability. We can only provide the scrambled version, which is useless without your password.\n\n**Q: What if I forget my password?**\nA: You'll need to set up encryption again with a new password. Old messages will be unreadable. Sorry‚Äîthat's the price of real privacy.\n\n**Q: Is this the same as Signal?**\nA: Similar concept, different implementation. [Signal](https://signal.org/) uses a more advanced protocol with additional protections. We use proven cryptography but simpler key management.\n\n**Q: Should I trust this for highly sensitive information?**\nA: We'd recommend dedicated secure messengers ([Signal](https://signal.org/), etc.) for extremely sensitive communications. ScriptHammer's encryption is solid for normal private conversations, but hasn't been audited like those specialized apps.\n\n## The Technical Details (For the Curious)\n\nIf you're interested in the specifics:\n\n- **Key derivation**: [Argon2id](https://cheatsheetseries.owasp.org/cheatsheets/Password%5FStorage%5FCheat%5FSheet.html#argon2id) (memory-hard, time-hard)\n- **Key exchange**: ECDH with P-256 curve\n- **Message encryption**: AES-256-GCM\n- **Random IV**: 96 bits per message\n\nThese are all industry-standard, [OWASP-recommended](https://owasp.org/) algorithms.\n\n---\n\n**Have questions about our security?** We're happy to discuss‚Äîtransparency is part of our commitment to you. Check out our [other blog posts](/blog/) or reach out anytime.\n",
      "excerpt": "Your messages on ScriptHammer are end-to-end encrypted. We explain how it works, how we compare to other platforms, and what limitations exist‚Äîhonestly.",
      "publishedAt": "2025-11-30T00:00:00.000Z",
      "updatedAt": "2025-11-30T00:00:00.000Z",
      "status": "published",
      "author": {
        "id": "default",
        "name": "ScriptHammer Team"
      },
      "metadata": {
        "tags": [
          "security",
          "encryption",
          "privacy",
          "e2e",
          "messaging"
        ],
        "categories": [
          "security",
          "transparency"
        ],
        "readingTime": 5,
        "wordCount": 850,
        "showToc": true,
        "showAuthor": true,
        "showShareButtons": true,
        "featured": true,
        "featuredImage": "/blog-images/message-encryption-security-explained/featured.png",
        "featuredImageAlt": "End-to-end encryption explained with lock icons and security badges showing AES-256 and Argon2id"
      },
      "seo": {
        "title": "Message Encryption: How We Protect Your Privacy",
        "description": "Learn how ScriptHammer's E2E encryption protects your messages. Discover our security vs Facebook, honest limitations, and why we can't read your DMs.",
        "keywords": [
          "end-to-end encryption",
          "private messaging",
          "secure messaging",
          "E2E encryption"
        ],
        "ogTitle": "Message Encryption: 5 Ways We Protect Your Privacy",
        "ogDescription": "Learn how ScriptHammer's E2E encryption works, compare to Facebook/Instagram/WhatsApp, and discover our honest security limitations.",
        "ogImage": "/blog-images/message-encryption-security-explained/featured-og.png",
        "twitterCard": "summary_large_image"
      }
    },
    {
      "id": "post_e6f87f22",
      "slug": "offline-payment-system-stripe-paypal",
      "title": "Offline Payment Integration: Stripe, PayPal & GDPR",
      "content": "\n# Offline-First Payment System: Stripe, PayPal & GDPR on Static Sites\n\nStatic sites (like GitHub Pages) don't have servers. So how do you accept payments without a backend? You can't run payment webhooks, you can't hide API (Application Programming Interface) keys, and you definitely can't store customer data in static files.\n\nThis post documents our solution: an offline-first payment system using [Supabase Edge Functions](https://supabase.com/docs/guides/functions), multiple payment providers (Stripe, PayPal, Cash App, Chime), General Data Protection Regulation (GDPR) consent management, and [IndexedDB](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API) queuing for network resilience. This isn't a Stripe checkout tutorial‚Äîthis is production-grade monetization for static sites.\n\n## üí≥ The Static Site Payment Problem\n\nStatic sites can't:\n\n1. **Process webhooks**: No server = no endpoint for Stripe/PayPal to POST payment confirmations\n2. **Hide secrets**: All JavaScript code is public, exposing API keys\n3. **Store payment data**: No database = payment records disappear on page refresh\n4. **Handle network failures**: Payment initiated offline has nowhere to go\n\nTraditional solutions like Stripe Checkout Links work for one-time payments but can't:\n\n- Track payment history per user\n- Handle subscriptions with retry logic\n- Verify webhook signatures (critical for security)\n- Queue operations when offline\n\nWe needed a real backend that doesn't require maintaining servers.\n\n## üóÑÔ∏è Why Supabase Edge Functions?\n\nAfter evaluating Vercel Functions, Netlify Functions, and AWS Lambda, we chose Supabase for four reasons:\n\n1. **Database Included**: PostgreSQL (Structured Query Language) for payment records, Row-Level Security (RLS) for data isolation, built-in authentication\n2. **Webhook-Ready**: Persistent endpoints that don't cold-start (Stripe requires <5s response time)\n3. **Type Safety**: Share TypeScript types between frontend and Edge Functions\n4. **No Vendor Lock-In**: Runs on Deno, open-source runtime\n\nVercel Functions are great for Next.js but require their hosting. AWS Lambda is enterprise-grade but complex. Supabase gives us enterprise features with static site simplicity.\n\n## üî® What We Built: Architecture Overview\n\nHere's the complete payment system architecture:\n\n### Payment Providers\n\n- **Stripe**: Credit card payments (one-time + subscriptions)\n- **PayPal**: PayPal balance + credit cards (one-time + subscriptions)\n- **Cash App**: Direct `$cashtag` links (no external scripts)\n- **Chime**: Direct `$chimesign` links (no external scripts)\n\n### Core Features\n\n- **One-Time Payments**: $1.00 - $999.99 with 5 currency support (USD, EUR, GBP, CAD, AUD)\n- **Recurring Subscriptions**: Monthly/yearly billing with automatic retry on failure\n- **Failed Payment Handling**: 3-day retry schedule with 7-day grace period\n- **Payment History**: Real-time dashboard with transaction details\n- **Webhook Verification**: Signature validation prevents fraudulent notifications\n\n### Privacy & GDPR Compliance\n\n- **Consent Modal**: Request permission before loading Stripe/PayPal scripts\n- **Data Transparency**: Explain what data is collected and by whom\n- **Consent Decline Fallback**: Show Cash App/Chime links (no scripts needed)\n\n### Offline-First Architecture\n\n- **IndexedDB Queue**: Store payment intents when offline\n- **Background Sync**: Automatic upload when connection returns\n- **Optimistic UI**: Instant feedback, sync in background\n\nLet's build it.\n\n## üîß Part 1: Payment Provider Setup\n\n### Stripe Configuration\n\nFirst, create a Stripe account at [stripe.com/dashboard](https://stripe.com/dashboard). Grab your **publishable key** (public) and **secret key** (private).\n\n```bash\n# .env (NEVER commit this file)\nNEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY=pk_test_...\nSTRIPE_SECRET_KEY=sk_test_...  # Used in Edge Functions only\nSTRIPE_WEBHOOK_SECRET=whsec_...  # For webhook signature verification\n```\n\nThe publishable key goes in frontend JavaScript. The secret key lives in Supabase Edge Functions (server-side).\n\n### PayPal Configuration\n\nPayPal is more complex‚Äîyou need both REST API credentials AND a client-side SDK:\n\n1. Create app at [developer.paypal.com/dashboard/applications](https://developer.paypal.com/dashboard/applications)\n2. Get Client ID (public) and Secret (private)\n3. Enable \"Subscriptions\" product in app settings\n\n```bash\n# .env\nNEXT_PUBLIC_PAYPAL_CLIENT_ID=AX... # Public\nPAYPAL_SECRET=EK...  # Edge Functions only\nPAYPAL_WEBHOOK_ID=WH-...  # For signature verification\n```\n\n### Cash App & Chime\n\nCash App and Chime use direct links‚Äîno API keys, no consent modals, no external scripts:\n\n```tsx\n// Direct payment links\nconst cashAppLink = `https://cash.app/$${CASHTAG}/${amount}`;\nconst chimeLink = `https://chime.com/pay/${CHIMESIGN}?amount=${amount}`;\n```\n\nThese are perfect GDPR-compliant fallbacks when users decline JavaScript consent.\n\n## üîí Part 2: GDPR Consent Modal\n\nBefore loading Stripe or PayPal JavaScript, we **must** ask for consent (GDPR Article 7 requirement):\n\n```tsx\n// src/components/payment/PaymentConsentModal/PaymentConsentModal.tsx\nimport { useState } from 'react';\n\nexport function PaymentConsentModal({\n  provider,\n  onAccept,\n  onDecline,\n}: {\n  provider: 'stripe' | 'paypal';\n  onAccept: () => void;\n  onDecline: () => void;\n}) {\n  const [loading, setLoading] = useState(false);\n\n  const providerInfo = {\n    stripe: {\n      name: 'Stripe',\n      url: 'https://stripe.com',\n      data: 'Payment card details, email address, billing address',\n      purpose: 'Process credit card payments securely',\n    },\n    paypal: {\n      name: 'PayPal',\n      url: 'https://paypal.com',\n      data: 'PayPal account information, email address',\n      purpose: 'Process PayPal and credit card payments',\n    },\n  };\n\n  const info = providerInfo[provider];\n\n  const handleAccept = async () => {\n    setLoading(true);\n    // Store consent in localStorage (not a cookie - user preference)\n    localStorage.setItem(`${provider}_consent`, 'granted');\n    onAccept();\n  };\n\n  const handleDecline = () => {\n    localStorage.setItem(`${provider}_consent`, 'denied');\n    onDecline();\n  };\n\n  return (\n    <div className=\"modal modal-open\">\n      <div className=\"modal-box\">\n        <h3 className=\"text-lg font-bold\">Payment Provider Consent</h3>\n\n        <div className=\"py-4\">\n          <p className=\"mb-4\">\n            To process payments via <strong>{info.name}</strong>, we need to\n            load their payment scripts. This will share some data with{' '}\n            {info.name}.\n          </p>\n\n          <div className=\"alert alert-info\">\n            <svg className=\"h-6 w-6 shrink-0 stroke-current\">\n              <path d=\"M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n            </svg>\n            <div>\n              <p className=\"font-semibold\">Data Shared with {info.name}:</p>\n              <p className=\"text-sm\">{info.data}</p>\n            </div>\n          </div>\n\n          <p className=\"mt-4 text-sm\">\n            <strong>Purpose:</strong> {info.purpose}\n            <br />\n            <strong>Third Party:</strong>{' '}\n            <a\n              href={info.url}\n              target=\"_blank\"\n              rel=\"noopener noreferrer\"\n              className=\"link\"\n            >\n              {info.name} Privacy Policy\n            </a>\n          </p>\n\n          <p className=\"text-base-content/70 mt-4 text-sm\">\n            <strong>Alternative:</strong> If you decline, you can still pay via\n            Cash App or Chime (no external scripts required).\n          </p>\n        </div>\n\n        <div className=\"modal-action\">\n          <button onClick={handleDecline} className=\"btn btn-ghost\">\n            Decline\n          </button>\n          <button\n            onClick={handleAccept}\n            className=\"btn btn-primary\"\n            disabled={loading}\n          >\n            {loading ? 'Loading...' : 'Accept & Continue'}\n          </button>\n        </div>\n      </div>\n    </div>\n  );\n}\n```\n\nThis modal:\n\n1. **Explains what data is shared** (GDPR transparency requirement)\n2. **Links to provider's privacy policy** (GDPR Article 13)\n3. **Offers alternative payment methods** (Cash App/Chime)\n4. **Stores consent in localStorage** (user preference, not tracking cookie)\n\n## üí∞ Part 3: Payment Intent Creation\n\nA **payment intent** represents the user's intention to pay before redirecting to Stripe/PayPal.\n\n### Frontend: Create Intent\n\n```tsx\n// src/lib/payments/payment-service.ts\nimport { supabase } from '@/lib/supabase/client';\nimport { validateMetadata } from '@/lib/payments/metadata-validator';\n\nexport async function createPaymentIntent({\n  amount,\n  currency = 'usd',\n  type,\n  interval,\n  description,\n  metadata = {},\n}: {\n  amount: number;\n  currency?: 'usd' | 'eur' | 'gbp' | 'cad' | 'aud';\n  type: 'one_time' | 'recurring';\n  interval?: 'month' | 'year';\n  description?: string;\n  metadata?: Record<string, unknown>;\n}) {\n  // Get authenticated user\n  const {\n    data: { user },\n  } = await supabase.auth.getUser();\n\n  if (!user) {\n    throw new Error('Must be authenticated to create payment');\n  }\n\n  // Validate metadata to prevent prototype pollution\n  const validatedMetadata = validateMetadata(metadata);\n\n  // Insert payment intent into database\n  const { data, error } = await supabase\n    .from('payment_intents')\n    .insert({\n      template_user_id: user.id, // Row-Level Security enforces this matches auth.uid()\n      amount, // Amount in cents (e.g., 1000 = $10.00)\n      currency,\n      type,\n      interval: type === 'recurring' ? interval : null,\n      description,\n      customer_email: user.email,\n      metadata: validatedMetadata,\n    })\n    .select()\n    .single();\n\n  if (error) {\n    throw new Error(`Failed to create payment intent: ${error.message}`);\n  }\n\n  return data;\n}\n```\n\n### Metadata Validation\n\nUser-provided metadata can't contain dangerous keys like `__proto__` or `constructor`, and must fit within size limits:\n\n```typescript\n// src/lib/payments/metadata-validator.ts\nconst DANGEROUS_KEYS = new Set([\n  '__proto__',\n  'constructor',\n  'prototype',\n  '__defineGetter__',\n  '__defineSetter__',\n  '__lookupGetter__',\n  '__lookupSetter__',\n]);\n\nconst MAX_METADATA_SIZE = 1024; // 1KB total\nconst MAX_NESTING_DEPTH = 2;\n\nexport function validateAndSanitizeMetadata(\n  metadata: unknown\n): Record<string, unknown> {\n  // Must be a plain object\n  if (!metadata || typeof metadata !== 'object' || Array.isArray(metadata)) {\n    throw new Error('Metadata must be a plain object');\n  }\n\n  // Check for prototype pollution at all levels\n  const pollutionError = checkPrototypePollution(metadata);\n  if (pollutionError) {\n    throw new Error(pollutionError);\n  }\n\n  // Check for circular references\n  if (hasCircularReferences(metadata)) {\n    throw new Error('Metadata cannot contain circular references');\n  }\n\n  // Check nesting depth (max 2 levels)\n  const nestingDepth = getNestingDepth(metadata);\n  if (nestingDepth > MAX_NESTING_DEPTH) {\n    throw new Error(`Metadata nesting exceeds ${MAX_NESTING_DEPTH} levels`);\n  }\n\n  // Check array limits (max 100 items per array)\n  const arrayError = checkArrayLimits(metadata);\n  if (arrayError) {\n    throw new Error(arrayError);\n  }\n\n  // Check total size limit (1KB for entire metadata object)\n  const serialized = JSON.stringify(metadata);\n  if (serialized.length > MAX_METADATA_SIZE) {\n    throw new Error(`Metadata exceeds 1KB limit`);\n  }\n\n  // Sanitize by removing dangerous keys\n  return sanitizeMetadata(metadata as Record<string, unknown>);\n}\n```\n\nThis prevents attacks like:\n\n```javascript\n// ‚ùå Attempt to pollute Object.prototype\ncreatePaymentIntent({\n  amount: 1000,\n  metadata: {\n    __proto__: { isAdmin: true }, // BLOCKED by validator\n  },\n});\n```\n\n## üí≥ Part 4: Stripe Payment Flow\n\n### Frontend: Redirect to Stripe Checkout\n\n```tsx\n// src/components/payment/PaymentButton/PaymentButton.tsx\nimport { loadStripe } from '@stripe/stripe-js';\nimport { createPaymentIntent } from '@/lib/payments/payment-service';\n\nexport function PaymentButton({\n  amount,\n  type,\n}: {\n  amount: number;\n  type: 'one_time' | 'recurring';\n}) {\n  const [loading, setLoading] = useState(false);\n\n  const handleStripePayment = async () => {\n    setLoading(true);\n\n    try {\n      // Check consent\n      const consent = localStorage.getItem('stripe_consent');\n      if (consent !== 'granted') {\n        // Show consent modal first\n        return;\n      }\n\n      // Create payment intent in database\n      const intent = await createPaymentIntent({\n        amount,\n        type,\n        currency: 'usd',\n      });\n\n      // Call Edge Function to create Stripe session\n      const { data, error } = await supabase.functions.invoke(\n        'stripe-create-payment',\n        {\n          body: { intent_id: intent.id },\n        }\n      );\n\n      if (error) throw error;\n\n      // Redirect to Stripe Checkout\n      const stripe = await loadStripe(\n        process.env.NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY!\n      );\n      const { error: redirectError } = await stripe!.redirectToCheckout({\n        sessionId: data.session_id,\n      });\n\n      if (redirectError) throw redirectError;\n    } catch (error) {\n      console.error('Stripe payment error:', error);\n      alert('Payment failed. Please try again.');\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  return (\n    <button\n      onClick={handleStripePayment}\n      disabled={loading}\n      className=\"btn btn-primary\"\n    >\n      {loading ? 'Processing...' : `Pay $${amount / 100} with Stripe`}\n    </button>\n  );\n}\n```\n\n### Edge Function: Stripe Checkout\n\n**‚ö†Ô∏è Note**: This is an example implementation. ScriptHammer currently uses `stripe-webhook` for webhook handling. You'll need to create this Edge Function in your own project and adapt it to your specific requirements.\n\n```typescript\n// supabase/functions/stripe-create-payment/index.ts (example implementation)\nimport { serve } from 'https://deno.land/std@0.168.0/http/server.ts';\nimport Stripe from 'https://esm.sh/stripe@12.0.0?target=deno';\nimport { createClient } from 'https://esm.sh/@supabase/supabase-js@2';\n\nconst stripe = new Stripe(Deno.env.get('STRIPE_SECRET_KEY')!, {\n  apiVersion: '2023-10-16',\n  httpClient: Stripe.createFetchHttpClient(),\n});\n\nserve(async (req) => {\n  try {\n    const { intent_id } = await req.json();\n\n    // Get payment intent from database\n    const supabase = createClient(\n      Deno.env.get('SUPABASE_URL')!,\n      Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')! // Service role bypasses RLS\n    );\n\n    const { data: intent, error } = await supabase\n      .from('payment_intents')\n      .select('*')\n      .eq('id', intent_id)\n      .single();\n\n    if (error || !intent) {\n      return new Response(\n        JSON.stringify({ error: 'Payment intent not found' }),\n        {\n          status: 404,\n          headers: { 'Content-Type': 'application/json' },\n        }\n      );\n    }\n\n    // Create Stripe Checkout Session\n    const session = await stripe.checkout.sessions.create({\n      payment_method_types: ['card'],\n      line_items: [\n        {\n          price_data: {\n            currency: intent.currency,\n            unit_amount: intent.amount,\n            product_data: {\n              name: intent.description || 'Payment',\n            },\n          },\n          quantity: 1,\n        },\n      ],\n      mode: intent.type === 'one_time' ? 'payment' : 'subscription',\n      success_url: `${req.headers.get('origin')}/payment-success?session_id={CHECKOUT_SESSION_ID}`,\n      cancel_url: `${req.headers.get('origin')}/payment-demo`,\n      customer_email: intent.customer_email,\n      metadata: {\n        intent_id: intent.id, // Link back to our database\n      },\n    });\n\n    return new Response(JSON.stringify({ session_id: session.id }), {\n      status: 200,\n      headers: { 'Content-Type': 'application/json' },\n    });\n  } catch (error) {\n    console.error('Stripe create payment error:', error);\n    return new Response(JSON.stringify({ error: error.message }), {\n      status: 500,\n      headers: { 'Content-Type': 'application/json' },\n    });\n  }\n});\n```\n\n## üîê Part 5: Webhook Verification\n\nWebhooks are **the only trustworthy payment confirmation**. Redirect callbacks can be faked‚Äîwebhooks can't (if you verify signatures).\n\n### Stripe Webhook Handler\n\n```typescript\n// supabase/functions/stripe-webhook/index.ts\nimport { serve } from 'https://deno.land/std@0.168.0/http/server.ts';\nimport Stripe from 'https://esm.sh/stripe@12.0.0?target=deno';\nimport { createClient } from 'https://esm.sh/@supabase/supabase-js@2';\n\nconst stripe = new Stripe(Deno.env.get('STRIPE_SECRET_KEY')!, {\n  apiVersion: '2023-10-16',\n  httpClient: Stripe.createFetchHttpClient(),\n});\n\nconst webhookSecret = Deno.env.get('STRIPE_WEBHOOK_SECRET')!;\n\nserve(async (req) => {\n  try {\n    const signature = req.headers.get('stripe-signature');\n    const body = await req.text();\n\n    // CRITICAL: Verify webhook signature\n    let event: Stripe.Event;\n    try {\n      event = stripe.webhooks.constructEvent(body, signature!, webhookSecret);\n    } catch (err) {\n      console.error('Webhook signature verification failed:', err.message);\n      return new Response(JSON.stringify({ error: 'Invalid signature' }), {\n        status: 400,\n        headers: { 'Content-Type': 'application/json' },\n      });\n    }\n\n    const supabase = createClient(\n      Deno.env.get('SUPABASE_URL')!,\n      Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!\n    );\n\n    // Store webhook event (idempotency - prevent duplicate processing)\n    const { error: eventError } = await supabase.from('webhook_events').insert({\n      provider: 'stripe',\n      provider_event_id: event.id,\n      event_type: event.type,\n      event_data: event.data,\n      signature: signature!,\n      signature_verified: true,\n    });\n\n    if (eventError) {\n      // Duplicate event ID - already processed\n      if (eventError.code === '23505') {\n        return new Response(JSON.stringify({ received: true }), {\n          status: 200,\n          headers: { 'Content-Type': 'application/json' },\n        });\n      }\n      throw eventError;\n    }\n\n    // Process event based on type\n    switch (event.type) {\n      case 'checkout.session.completed': {\n        const session = event.data.object as Stripe.Checkout.Session;\n\n        // Record payment result\n        await supabase.from('payment_results').insert({\n          intent_id: session.metadata?.intent_id,\n          provider: 'stripe',\n          transaction_id: session.id,\n          status: 'succeeded',\n          charged_amount: session.amount_total,\n          charged_currency: session.currency,\n          webhook_verified: true,\n          verification_method: 'webhook',\n        });\n\n        // Mark webhook as processed\n        await supabase\n          .from('webhook_events')\n          .update({ processed: true, processed_at: new Date().toISOString() })\n          .eq('provider_event_id', event.id);\n\n        break;\n      }\n\n      case 'invoice.payment_failed': {\n        const invoice = event.data.object as Stripe.Invoice;\n\n        // Increment failed payment counter for subscription\n        const { data: subscription } = await supabase\n          .from('subscriptions')\n          .select('failed_payment_count')\n          .eq('provider_subscription_id', invoice.subscription as string)\n          .single();\n\n        if (subscription) {\n          const failedCount = (subscription.failed_payment_count || 0) + 1;\n\n          // Update retry schedule\n          await supabase\n            .from('subscriptions')\n            .update({\n              failed_payment_count: failedCount,\n              status: failedCount >= 3 ? 'grace_period' : 'past_due',\n              grace_period_expires:\n                failedCount >= 3\n                  ? new Date(Date.now() + 7 * 24 * 60 * 60 * 1000).toISOString()\n                  : null,\n            })\n            .eq('provider_subscription_id', invoice.subscription as string);\n        }\n\n        break;\n      }\n    }\n\n    return new Response(JSON.stringify({ received: true }), {\n      status: 200,\n      headers: { 'Content-Type': 'application/json' },\n    });\n  } catch (error) {\n    console.error('Stripe webhook error:', error);\n    return new Response(JSON.stringify({ error: error.message }), {\n      status: 500,\n      headers: { 'Content-Type': 'application/json' },\n    });\n  }\n});\n```\n\n### Webhook Security Checklist\n\n‚úÖ **Verify signature** before processing (prevents fake webhooks)\n‚úÖ **Store event ID** to prevent duplicate processing (idempotency)\n‚úÖ **Return 200 quickly** (<5 seconds or Stripe retries)\n‚úÖ **Process asynchronously** if operations take >5 seconds\n‚úÖ **Log failures** for manual retry\n\n## üì¶ Part 6: Offline-First with IndexedDB\n\nNetwork failures happen. Users click \"Pay\" on the subway, at coffee shops, on airplanes. We queue operations locally and sync when connection returns.\n\n### IndexedDB Queue Setup\n\n```typescript\n// src/lib/payments/offline-queue.ts\nimport Dexie, { type Table } from 'dexie';\n\nexport interface QueuedPayment {\n  id?: number;\n  intent_id: string;\n  provider: 'stripe' | 'paypal';\n  amount: number;\n  currency: string;\n  created_at: number;\n  retry_count: number;\n}\n\nclass OfflineQueue extends Dexie {\n  payments!: Table<QueuedPayment>;\n\n  constructor() {\n    super('PaymentQueue');\n    this.version(1).stores({\n      payments: '++id, intent_id, provider, created_at',\n    });\n  }\n}\n\nconst db = new OfflineQueue();\n\nexport async function queuePayment(\n  payment: Omit<QueuedPayment, 'id' | 'created_at' | 'retry_count'>\n) {\n  await db.payments.add({\n    ...payment,\n    created_at: Date.now(),\n    retry_count: 0,\n  });\n}\n\nexport async function processQueue() {\n  const queuedPayments = await db.payments.toArray();\n\n  for (const payment of queuedPayments) {\n    try {\n      // Attempt to sync with backend\n      const { error } = await supabase.functions.invoke(\n        `${payment.provider}-create-payment`,\n        {\n          body: { intent_id: payment.intent_id },\n        }\n      );\n\n      if (!error) {\n        // Success - remove from queue\n        await db.payments.delete(payment.id!);\n      } else {\n        // Increment retry count\n        await db.payments.update(payment.id!, {\n          retry_count: payment.retry_count + 1,\n        });\n\n        // Delete after 3 failed retries\n        if (payment.retry_count >= 3) {\n          await db.payments.delete(payment.id!);\n        }\n      }\n    } catch (error) {\n      console.error('Failed to process queued payment:', error);\n    }\n  }\n}\n\n// Listen for online event\nif (typeof window !== 'undefined') {\n  window.addEventListener('online', () => {\n    console.log('Network reconnected - processing payment queue');\n    processQueue();\n  });\n}\n```\n\n### Usage in Payment Button\n\n```tsx\nconst handlePayment = async () => {\n  try {\n    // Create payment intent\n    const intent = await createPaymentIntent({ amount, type, currency });\n\n    // Check if online\n    if (!navigator.onLine) {\n      // Queue for later\n      await queuePayment({\n        intent_id: intent.id,\n        provider: 'stripe',\n        amount,\n        currency,\n      });\n\n      alert('You are offline. Payment will process when connection returns.');\n      return;\n    }\n\n    // Online - process immediately\n    const { data } = await supabase.functions.invoke('stripe-create-payment', {\n      body: { intent_id: intent.id },\n    });\n\n    // Redirect to checkout\n    const stripe = await loadStripe(\n      process.env.NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY!\n    );\n    await stripe!.redirectToCheckout({ sessionId: data.session_id });\n  } catch (error) {\n    console.error('Payment error:', error);\n  }\n};\n```\n\n## üîÑ Part 7: Subscription Retry Logic\n\nWhen a subscription payment fails, Stripe retries automatically. We enhance this with custom retry schedules and grace periods:\n\n### Failed Payment Retry Schedule\n\n```typescript\n// Retry schedule: Day 1, Day 3, Day 7\nconst RETRY_SCHEDULE = {\n  day_1: 1 * 24 * 60 * 60 * 1000, // 1 day in milliseconds\n  day_3: 3 * 24 * 60 * 60 * 1000,\n  day_7: 7 * 24 * 60 * 60 * 1000,\n};\n\n// When payment fails (from webhook)\nasync function handlePaymentFailure(subscriptionId: string) {\n  const { data: subscription } = await supabase\n    .from('subscriptions')\n    .select('*')\n    .eq('provider_subscription_id', subscriptionId)\n    .single();\n\n  if (!subscription) return;\n\n  const failedCount = subscription.failed_payment_count + 1;\n\n  // Update retry tracking\n  const retrySchedule = subscription.retry_schedule || {\n    day_1: false,\n    day_3: false,\n    day_7: false,\n  };\n\n  if (failedCount === 1) {\n    retrySchedule.day_1 = true;\n  } else if (failedCount === 2) {\n    retrySchedule.day_3 = true;\n  } else if (failedCount === 3) {\n    retrySchedule.day_7 = true;\n  }\n\n  await supabase\n    .from('subscriptions')\n    .update({\n      failed_payment_count: failedCount,\n      retry_schedule: retrySchedule,\n      status: failedCount >= 3 ? 'grace_period' : 'past_due',\n      grace_period_expires:\n        failedCount >= 3\n          ? new Date(Date.now() + 7 * 24 * 60 * 60 * 1000).toISOString()\n          : null,\n    })\n    .eq('id', subscription.id);\n\n  // Send notification to user\n  await sendPaymentFailureEmail(subscription.customer_email, failedCount);\n}\n```\n\nAfter 3 failed retries, the subscription enters a **7-day grace period**. If payment succeeds during grace, resume subscription. If grace expires, cancel subscription.\n\n## üí° Part 8: What We Learned\n\n### Lesson 1: Webhook Idempotency Required\n\nStripe sends duplicate webhooks. Without idempotency checks, you'll double-charge customers or double-credit accounts.\n\n**Solution**: Store `provider_event_id` with UNIQUE constraint:\n\n```sql\nCREATE UNIQUE INDEX idx_webhook_events_provider_event_id\n  ON webhook_events(provider, provider_event_id);\n```\n\nWhen inserting fails with error code `23505` (duplicate key), **return 200** to Stripe (event already processed).\n\n### Lesson 2: Use Webhook Forwarding\n\nStripe can't POST to `localhost:3000`. Use [Stripe CLI](https://stripe.com/docs/stripe-cli) to forward webhooks during development:\n\n```bash\n# Install Stripe CLI\nbrew install stripe/stripe-cli/stripe\n\n# Forward webhooks to local Supabase function\nstripe listen --forward-to https://your-project.supabase.co/functions/v1/stripe-webhook\n```\n\nThis gives you **real webhook events** in development, exposing edge cases you'd miss with mocked data.\n\n### Lesson 3: GDPR Fallback Options\n\nYou can't force users to accept JavaScript. If they decline Stripe/PayPal consent, **you must provide alternatives**:\n\n- Cash App links (no scripts)\n- Chime links (no scripts)\n- Bank transfer instructions\n- Crypto payment addresses\n\nWithout fallbacks, declining consent = no payment = lost revenue.\n\n### Lesson 4: Validate Metadata Security\n\nUser-provided metadata goes into JSON columns. Without validation, attackers can inject:\n\n```javascript\n// ‚ùå Prototype pollution attack\n{\n  \"__proto__\": {\n    \"isAdmin\": true\n  }\n}\n```\n\n**Solution**: Reject dangerous keys (`__proto__`, `constructor`, `prototype`) and limit metadata size.\n\n### Lesson 5: Handle Partial Failures\n\nNetwork can fail mid-request. IndexedDB queue must handle:\n\n1. **Payment intent created** but Edge Function call failed ‚Üí Queue with intent ID\n2. **Edge Function succeeded** but Stripe API failed ‚Üí Retry with same intent ID (Stripe handles duplicates)\n3. **Stripe succeeded** but webhook lost ‚Üí Webhook retry handles this\n\n**Never delete from queue until webhook confirms payment.**\n\n## ‚úÖ Conclusion: Payments Without Servers\n\nStatic sites can't run servers, but they can:\n\n1. **Delegate backend to Supabase Edge Functions** (webhook endpoints, database storage)\n2. **Queue operations offline with IndexedDB** (network resilience)\n3. **Verify webhooks cryptographically** (prevent fake confirmations)\n4. **Comply with GDPR** (consent modals, privacy-preserving fallbacks)\n\nThe result? A production-grade payment system that works on GitHub Pages, scales to thousands of transactions, and respects user privacy.\n\nFor authentication to protect these payments, read: [Production-Ready Authentication with Supabase](/blog/authentication-supabase-oauth).\n\n---\n\n**Want to see the full implementation?** Check out the [ScriptHammer GitHub repository](https://github.com/TortoiseWolfe/ScriptHammer).\n",
      "excerpt": "Learn how to build offline-first payments on GitHub Pages with Supabase Edge Functions, Stripe, PayPal, GDPR consent, and IndexedDB resilience.",
      "publishedAt": "2025-10-09T00:00:00.000Z",
      "updatedAt": "2025-10-08T14:56:47.756Z",
      "status": "published",
      "author": {
        "id": "default",
        "name": "TortoiseWolfe"
      },
      "metadata": {
        "tags": [
          "payments",
          "stripe",
          "paypal",
          "supabase",
          "edge-functions",
          "offline-first",
          "gdpr"
        ],
        "categories": [
          "tutorials",
          "monetization"
        ],
        "readingTime": 16,
        "wordCount": 3143,
        "showToc": true,
        "showAuthor": true,
        "showShareButtons": true,
        "featured": false,
        "featuredImage": "/blog-images/offline-payment-system-stripe-paypal/featured-og.svg",
        "featuredImageAlt": "Offline-First Payment System with Stripe, PayPal, Supabase Edge Functions, and GDPR Consent"
      },
      "seo": {
        "title": "Offline Payment Integration: Stripe, PayPal & GDPR",
        "description": "Learn how to build offline-first payments on GitHub Pages with Supabase Edge Functions, Stripe, PayPal, GDPR consent, and IndexedDB resilience.",
        "keywords": [
          "payments",
          "stripe",
          "paypal",
          "supabase",
          "edge-functions",
          "offline-first",
          "gdpr"
        ],
        "ogTitle": "Offline-First Payment System - Stripe, PayPal & Static Sites",
        "ogDescription": "Complete guide to implementing payments on GitHub Pages using Supabase Edge Functions, multiple providers, GDPR compliance, and offline-first architecture with IndexedDB.",
        "ogImage": "/blog-images/offline-payment-system-stripe-paypal/featured-og.png",
        "twitterCard": "summary_large_image"
      },
      "frontMatter": {
        "title": "Offline Payment Integration: Stripe, PayPal & GDPR",
        "author": "TortoiseWolfe",
        "date": "2025-10-09T00:00:00.000Z",
        "slug": "offline-payment-system-stripe-paypal",
        "tags": [
          "payments",
          "stripe",
          "paypal",
          "supabase",
          "edge-functions",
          "offline-first",
          "gdpr"
        ],
        "categories": [
          "tutorials",
          "monetization"
        ],
        "excerpt": "Learn how to build offline-first payments on GitHub Pages with Supabase Edge Functions, Stripe, PayPal, GDPR consent, and IndexedDB resilience.",
        "featuredImage": "/blog-images/offline-payment-system-stripe-paypal/featured-og.svg",
        "featuredImageAlt": "Offline-First Payment System with Stripe, PayPal, Supabase Edge Functions, and GDPR Consent",
        "ogImage": "/blog-images/offline-payment-system-stripe-paypal/featured-og.png",
        "ogTitle": "Offline-First Payment System - Stripe, PayPal & Static Sites",
        "ogDescription": "Complete guide to implementing payments on GitHub Pages using Supabase Edge Functions, multiple providers, GDPR compliance, and offline-first architecture with IndexedDB.",
        "twitterCard": "summary_large_image"
      }
    },
    {
      "id": "post_421e318f",
      "slug": "authentication-supabase-oauth",
      "title": "Supabase Authentication: OAuth & Security Guide",
      "content": "\n# üîí Production-Ready Authentication with Supabase: OAuth, Security, and Real-World Implementation\n\nAuthentication is the foundation of any application that handles user data. Get it wrong, and you're exposing your users to account takeovers, data breaches, and compliance nightmares. Get it right, and your users don't even notice‚Äîthey just trust you.\n\nThis post documents our implementation of production-ready authentication in ScriptHammer using [Supabase](https://supabase.com/), complete with OAuth (Open Authorization) providers, server-side rate limiting, and database-level security policies. This isn't a \"hello world\" tutorial‚Äîthis is what we learned building authentication that actually ships to production.\n\n## üóÑÔ∏è Why Supabase? (vs Auth0/Firebase)\n\nAfter evaluating Auth0, Firebase Auth, and Supabase, we chose Supabase for three critical reasons:\n\n1. **Database-First Security**: Row-Level Security (RLS) policies live in PostgreSQL (Structured Query Language), not application code. Even if your API (Application Programming Interface) gets compromised, the database won't leak data.\n\n2. **No Vendor Lock-In**: Supabase runs on open-source PostgreSQL. If we ever need to migrate, we own the database schema and can export everything.\n\n3. **Developer Experience**: Built-in session management with [@supabase/ssr](https://github.com/supabase/auth-helpers) for Next.js, automatic TypeScript type generation, and real-time subscriptions all in one package.\n\nFirebase Auth is great for prototypes, but authentication-as-a-service means you're always dependent on Google's infrastructure. Auth0 is enterprise-grade but expensive at scale. Supabase gives us enterprise features with open-source flexibility.\n\n## üî® What We Built: Feature Overview\n\nHere's what ships in our authentication system:\n\n### üîê Core Authentication Flows\n\n- ‚úâÔ∏è **Email/Password Authentication**: Traditional sign-up with email verification\n- üîë **OAuth Providers**: GitHub and Google single sign-on with Cross-Site Request Forgery (CSRF) protection\n- üîÑ **Password Reset**: Secure token-based password recovery via email\n- ‚è±Ô∏è **Session Management**: 7-day default sessions, 30-day \"Remember Me\" option\n\n### üõ°Ô∏è Security Hardening\n\n- üö¶ **Server-Side Rate Limiting**: 5 failed attempts per 15-minute window, enforced in PostgreSQL (client can't bypass)\n- üîí **OAuth CSRF Protection**: State token validation prevents session hijacking\n- üìù **Audit Logging**: Every authentication event logged to database with Internet Protocol (IP) address and user agent\n- üóÑÔ∏è **Row-Level Security**: Database policies ensure users only see their own data\n\n### üîß Developer Features\n\n- üõ£Ô∏è **Protected Routes**: Middleware-based authorization checks\n- üìò **Type Safety**: Generated TypeScript types from Supabase schema\n- ‚öõÔ∏è **React Context**: Global `useAuth()` hook for accessing user session\n- üß™ **Test Infrastructure**: Pre-configured test users for integration testing\n\nLet's dive into the implementation.\n\n## üìß Part 1: Email/Password Auth\n\n### The Sign-Up Flow\n\nEmail/password authentication starts with user registration. Here's our `SignUpForm` component:\n\n```tsx\n// src/components/auth/SignUpForm/SignUpForm.tsx\nimport { useState } from 'react';\nimport { supabase } from '@/lib/supabase/client';\nimport { validateEmail } from '@/lib/auth/email-validator';\nimport { checkRateLimit } from '@/lib/auth/rate-limit-check';\n\nexport function SignUpForm() {\n  const [email, setEmail] = useState('');\n  const [password, setPassword] = useState('');\n  const [loading, setLoading] = useState(false);\n\n  const handleSignUp = async (e: React.FormEvent) => {\n    e.preventDefault();\n    setLoading(true);\n\n    try {\n      // Validate email format and check for disposable domains\n      const emailValidation = validateEmail(email);\n      if (!emailValidation.valid) {\n        alert(emailValidation.errors.join(', '));\n        return;\n      }\n\n      // Server-side rate limit check (enforced in PostgreSQL)\n      const rateLimit = await checkRateLimit(email, 'sign_up');\n      if (!rateLimit.allowed) {\n        alert(`Too many attempts. Try again after ${rateLimit.locked_until}`);\n        return;\n      }\n\n      // Create user with Supabase Auth\n      const { data, error } = await supabase.auth.signUp({\n        email,\n        password,\n        options: {\n          emailRedirectTo: `${window.location.origin}/auth/callback`,\n        },\n      });\n\n      if (error) throw error;\n\n      // User created - verification email sent\n      alert('Check your email for the verification link!');\n    } catch (error) {\n      console.error('Sign up error:', error);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  return (\n    <form onSubmit={handleSignUp}>\n      <input\n        type=\"email\"\n        value={email}\n        onChange={(e) => setEmail(e.target.value)}\n        placeholder=\"Email address\"\n        required\n      />\n      <input\n        type=\"password\"\n        value={password}\n        onChange={(e) => setPassword(e.target.value)}\n        placeholder=\"Password (min 8 chars)\"\n        minLength={8}\n        required\n      />\n      <button type=\"submit\" disabled={loading}>\n        {loading ? 'Creating account...' : 'Sign Up'}\n      </button>\n    </form>\n  );\n}\n```\n\n### Email Validation with TLD Checks\n\nWe enhanced Supabase's built-in validation with custom checks for Top-Level Domain (TLD) validity and disposable email detection:\n\n```typescript\n// src/lib/auth/email-validator.ts\nconst VALID_TLDS = new Set([\n  'com',\n  'org',\n  'net',\n  'edu',\n  'gov',\n  'io',\n  'co',\n  'uk',\n  'us',\n  'ca',\n  'au',\n  'de',\n  'fr',\n  'it',\n  'es',\n  'app',\n  'dev',\n  'cloud',\n  'tech',\n  'ai',\n]);\n\nconst DISPOSABLE_DOMAINS = new Set([\n  'tempmail.com',\n  'throwaway.email',\n  '10minutemail.com',\n  'guerrillamail.com',\n  'mailinator.com',\n]);\n\nexport function validateEmail(email: string) {\n  const errors: string[] = [];\n  const warnings: string[] = [];\n\n  // RFC 5322 format check\n  const EMAIL_REGEX =\n    /^[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+@[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)*$/;\n\n  if (!EMAIL_REGEX.test(email)) {\n    errors.push('Invalid email format');\n  }\n\n  // TLD validation\n  const tld = email.split('.').pop()?.toLowerCase();\n  if (!tld || !VALID_TLDS.has(tld)) {\n    errors.push('Invalid or missing top-level domain (TLD)');\n  }\n\n  // Disposable email detection (warning, not error)\n  const domain = email.split('@')[1];\n  if (domain && DISPOSABLE_DOMAINS.has(domain)) {\n    warnings.push(\n      'Disposable email detected - account recovery may be limited'\n    );\n  }\n\n  return {\n    valid: errors.length === 0,\n    errors,\n    warnings,\n    normalized: email.toLowerCase(),\n  };\n}\n```\n\nWhy validate on the client AND server? Client validation provides instant feedback. Server validation (in Supabase Edge Functions) prevents malicious clients from bypassing checks.\n\n### Email Verification Flow\n\nAfter sign-up, Supabase sends a verification email with a token. The user clicks the link, which redirects to our callback page:\n\n```tsx\n// src/app/auth/callback/page.tsx\nimport { createClient } from '@/lib/supabase/server';\nimport { redirect } from 'next/navigation';\n\nexport default async function AuthCallbackPage({\n  searchParams,\n}: {\n  searchParams: { code?: string };\n}) {\n  const supabase = await createClient();\n\n  if (searchParams.code) {\n    // Exchange authorization code for session\n    const { error } = await supabase.auth.exchangeCodeForSession(\n      searchParams.code\n    );\n\n    if (error) {\n      return redirect('/sign-in?error=verification_failed');\n    }\n\n    // Email verified - redirect to dashboard\n    return redirect('/profile');\n  }\n\n  return redirect('/sign-in');\n}\n```\n\nThis callback handles both email verification and OAuth redirects (which we'll cover next).\n\n## üîë Part 2: OAuth with GitHub and Google\n\n### Why OAuth?\n\nPassword fatigue is real. Users reuse passwords across sites, creating security nightmares. OAuth lets users authenticate with providers they already trust (GitHub, Google) without creating another password.\n\n### OAuth Flow with CSRF Protection\n\nOAuth has a critical vulnerability: Cross-Site Request Forgery (CSRF) attacks. An attacker can initiate an OAuth flow and trick a victim into completing it, linking the attacker's GitHub account to the victim's app account.\n\nWe prevent this with **state tokens**:\n\n```typescript\n// src/lib/auth/oauth-state.ts\nimport { supabase } from '@/lib/supabase/client';\n\n// Generate UUID v4 using crypto API (available in modern browsers and Node 16+)\nfunction generateUUID(): string {\n  if (typeof crypto !== 'undefined' && crypto.randomUUID) {\n    return crypto.randomUUID();\n  }\n  // Fallback for older environments\n  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, (c) => {\n    const r = (Math.random() * 16) | 0;\n    const v = c === 'x' ? r : (r & 0x3) | 0x8;\n    return v.toString(16);\n  });\n}\n\n/**\n * Get or create a session ID for CSRF validation\n * Uses sessionStorage to track the browser session\n */\nfunction getSessionId(): string {\n  if (typeof window === 'undefined') {\n    return '';\n  }\n\n  const SESSION_KEY = 'oauth_session_id';\n  let sessionId = sessionStorage.getItem(SESSION_KEY);\n\n  if (!sessionId) {\n    sessionId = generateUUID();\n    sessionStorage.setItem(SESSION_KEY, sessionId);\n  }\n\n  return sessionId;\n}\n\n/**\n * Generate a cryptographically random state token for OAuth flow\n * Stored in database with 5-minute expiration\n */\nexport async function generateOAuthState(\n  provider: 'github' | 'google'\n): Promise<string> {\n  const stateToken = generateUUID(); // Cryptographically random UUID\n  const sessionId = getSessionId(); // Get or create browser session ID\n\n  // Store in database\n  const { error } = await supabase.from('oauth_states').insert({\n    state_token: stateToken,\n    provider,\n    session_id: sessionId, // Tie to browser session\n    expires_at: new Date(Date.now() + 5 * 60 * 1000).toISOString(), // 5 minutes\n  });\n\n  if (error) {\n    throw new Error('Failed to generate OAuth state');\n  }\n\n  return stateToken;\n}\n\n/**\n * Validate state token from OAuth callback\n * Ensures the request originated from the same browser session\n */\nexport async function validateOAuthState(stateToken: string) {\n  const { data, error } = await supabase\n    .from('oauth_states')\n    .select('*')\n    .eq('state_token', stateToken)\n    .eq('used', false) // Prevent replay attacks\n    .single();\n\n  if (error || !data) {\n    return { valid: false, error: 'invalid_state' };\n  }\n\n  // Check expiration\n  if (new Date(data.expires_at) < new Date()) {\n    return { valid: false, error: 'state_expired' };\n  }\n\n  // Mark as used (single-use tokens)\n  await supabase\n    .from('oauth_states')\n    .update({ used: true })\n    .eq('state_token', stateToken);\n\n  return { valid: true, provider: data.provider };\n}\n```\n\n### OAuth Button Component\n\nHere's how we initiate OAuth flows with state token protection:\n\n```tsx\n// src/components/auth/OAuthButtons/OAuthButtons.tsx\nimport { supabase } from '@/lib/supabase/client';\nimport { generateOAuthState } from '@/lib/auth/oauth-state';\n\nexport function OAuthButtons() {\n  const handleOAuth = async (provider: 'github' | 'google') => {\n    try {\n      // Generate CSRF protection state token\n      const stateToken = await generateOAuthState(provider);\n\n      // Initiate OAuth flow with state parameter\n      const { data, error } = await supabase.auth.signInWithOAuth({\n        provider,\n        options: {\n          redirectTo: `${window.location.origin}/auth/callback`,\n          scopes:\n            provider === 'github' ? 'read:user user:email' : 'email profile',\n          queryParams: {\n            state: stateToken, // Include state for CSRF protection\n          },\n        },\n      });\n\n      if (error) throw error;\n\n      // User redirected to provider's consent page\n    } catch (error) {\n      console.error('OAuth error:', error);\n      alert('Failed to initiate OAuth flow');\n    }\n  };\n\n  return (\n    <div className=\"flex flex-col gap-3\">\n      <button onClick={() => handleOAuth('github')} className=\"btn btn-outline\">\n        <svg /* GitHub icon SVG */></svg>\n        Continue with GitHub\n      </button>\n\n      <button onClick={() => handleOAuth('google')} className=\"btn btn-outline\">\n        <svg /* Google icon SVG */></svg>\n        Continue with Google\n      </button>\n    </div>\n  );\n}\n```\n\n### OAuth Callback Handling\n\nWhen the user authorizes on GitHub/Google, they're redirected back to our callback with an authorization code. We validate the state token before exchanging the code for a session:\n\n```tsx\n// src/app/auth/callback/page.tsx (extended)\nimport { validateOAuthState } from '@/lib/auth/oauth-state';\n\nexport default async function AuthCallbackPage({\n  searchParams,\n}: {\n  searchParams: { code?: string; state?: string };\n}) {\n  const supabase = await createClient();\n\n  if (searchParams.code) {\n    // Validate OAuth state token (CSRF protection)\n    if (searchParams.state) {\n      const stateValidation = await validateOAuthState(searchParams.state);\n\n      if (!stateValidation.valid) {\n        return redirect('/sign-in?error=oauth_security_error');\n      }\n    }\n\n    // Exchange authorization code for session\n    const { error } = await supabase.auth.exchangeCodeForSession(\n      searchParams.code\n    );\n\n    if (error) {\n      return redirect('/sign-in?error=oauth_failed');\n    }\n\n    // Authenticated - redirect to dashboard\n    return redirect('/profile');\n  }\n\n  return redirect('/sign-in');\n}\n```\n\n## üö¶ Part 3: Server-Side Rate Limiting\n\n‚ö†Ô∏è **Critical**: Client-side rate limiting is useless‚Äîattackers can bypass JavaScript. We implemented **PostgreSQL-based rate limiting** that's impossible to bypass:\n\n### Database Function for Rate Limiting\n\n```sql\n-- supabase/migrations/20251006_complete_monolithic_setup.sql\nCREATE TABLE rate_limit_attempts (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  identifier TEXT NOT NULL, -- Email or IP address\n  attempt_type TEXT NOT NULL CHECK (attempt_type IN ('sign_in', 'sign_up', 'password_reset')),\n  ip_address INET,\n  user_agent TEXT,\n  window_start TIMESTAMPTZ NOT NULL DEFAULT now(),\n  attempt_count INTEGER NOT NULL DEFAULT 1,\n  locked_until TIMESTAMPTZ, -- Lockout expiration\n  created_at TIMESTAMPTZ NOT NULL DEFAULT now(),\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT now()\n);\n\nCREATE UNIQUE INDEX idx_rate_limit_unique\n  ON rate_limit_attempts(identifier, attempt_type);\n\n-- Function: Check if user is rate limited\nCREATE OR REPLACE FUNCTION check_rate_limit(\n  p_identifier TEXT,\n  p_attempt_type TEXT,\n  p_ip_address INET DEFAULT NULL\n)\nRETURNS JSON AS $$\nDECLARE\n  v_record rate_limit_attempts%ROWTYPE;\n  v_max_attempts INTEGER := 5;\n  v_window_minutes INTEGER := 15;\n  v_now TIMESTAMPTZ := now();\nBEGIN\n  -- Lock row to prevent race conditions\n  SELECT * INTO v_record\n  FROM rate_limit_attempts\n  WHERE identifier = p_identifier AND attempt_type = p_attempt_type\n  FOR UPDATE SKIP LOCKED;\n\n  -- Check if locked out\n  IF v_record.locked_until IS NOT NULL AND v_record.locked_until > v_now THEN\n    RETURN json_build_object(\n      'allowed', FALSE,\n      'remaining', 0,\n      'locked_until', v_record.locked_until,\n      'reason', 'rate_limited'\n    );\n  END IF;\n\n  -- Reset window if expired\n  IF v_record.id IS NULL OR (v_now - v_record.window_start) > (v_window_minutes || ' minutes')::INTERVAL THEN\n    INSERT INTO rate_limit_attempts (identifier, attempt_type, ip_address, window_start, attempt_count)\n    VALUES (p_identifier, p_attempt_type, p_ip_address, v_now, 0)\n    ON CONFLICT (identifier, attempt_type) DO UPDATE\n      SET window_start = v_now, attempt_count = 0, locked_until = NULL, updated_at = v_now;\n    RETURN json_build_object('allowed', TRUE, 'remaining', v_max_attempts, 'locked_until', NULL);\n  END IF;\n\n  -- Check attempt count\n  IF v_record.attempt_count < v_max_attempts THEN\n    RETURN json_build_object(\n      'allowed', TRUE,\n      'remaining', v_max_attempts - v_record.attempt_count,\n      'locked_until', NULL\n    );\n  ELSE\n    -- Lock out user\n    UPDATE rate_limit_attempts\n    SET locked_until = v_now + (v_window_minutes || ' minutes')::INTERVAL, updated_at = v_now\n    WHERE identifier = p_identifier AND attempt_type = p_attempt_type;\n\n    RETURN json_build_object(\n      'allowed', FALSE,\n      'remaining', 0,\n      'locked_until', v_now + (v_window_minutes || ' minutes')::INTERVAL,\n      'reason', 'rate_limited'\n    );\n  END IF;\nEND;\n$$ LANGUAGE plpgsql SECURITY DEFINER;\n```\n\n### Client-Side Rate Limit Check\n\n```typescript\n// src/lib/auth/rate-limit-check.ts\nimport { supabase } from '@/lib/supabase/client';\n\nexport interface RateLimitResult {\n  allowed: boolean;\n  remaining: number;\n  locked_until: string | null;\n  reason?: 'rate_limited';\n}\n\nexport async function checkRateLimit(\n  identifier: string,\n  attemptType: 'sign_in' | 'sign_up' | 'password_reset',\n  ipAddress?: string\n): Promise<RateLimitResult> {\n  const { data, error } = await supabase.rpc('check_rate_limit', {\n    p_identifier: identifier,\n    p_attempt_type: attemptType,\n    p_ip_address: ipAddress || null,\n  });\n\n  if (error) {\n    console.error('Rate limit check failed:', error);\n    // Fail open (allow request) rather than fail closed (block everyone)\n    return { allowed: true, remaining: 5, locked_until: null };\n  }\n\n  return data as unknown as RateLimitResult;\n}\n\nexport async function recordFailedAttempt(\n  identifier: string,\n  attemptType: 'sign_in' | 'sign_up' | 'password_reset',\n  ipAddress?: string\n): Promise<void> {\n  await supabase.rpc('record_failed_attempt', {\n    p_identifier: identifier,\n    p_attempt_type: attemptType,\n    p_ip_address: ipAddress || null,\n  });\n}\n```\n\nThis approach has three critical advantages:\n\n1. **Impossible to Bypass**: Enforced in PostgreSQL, not JavaScript\n2. **No External Services**: No Redis or Upstash needed\n3. **Audit Trail**: Every attempt logged with IP and user agent\n\n## üóÑÔ∏è Part 4: Row-Level Security (RLS) Policies\n\nEven if your API gets compromised, Row-Level Security (RLS) policies in PostgreSQL ensure users can't see each other's data.\n\n### Payment Data Isolation\n\n```sql\n-- Users can only view their own payment intents\nCREATE POLICY \"Users can view own payment intents\" ON payment_intents\n  FOR SELECT USING (auth.uid() = template_user_id);\n\n-- Users can only create payment intents for themselves\nCREATE POLICY \"Users can create own payment intents\" ON payment_intents\n  FOR INSERT WITH CHECK (auth.uid() = template_user_id);\n\n-- Payment intents are immutable (no UPDATE allowed)\nCREATE POLICY \"Payment intents are immutable\" ON payment_intents\n  FOR UPDATE USING (false);\n\n-- Users cannot delete payment records\nCREATE POLICY \"Payment intents cannot be deleted by users\" ON payment_intents\n  FOR DELETE USING (false);\n```\n\n### User Profile Access\n\n```sql\n-- Users view their own profile\nCREATE POLICY \"Users view own profile\" ON user_profiles\n  FOR SELECT USING (auth.uid() = id);\n\n-- Users update their own profile\nCREATE POLICY \"Users update own profile\" ON user_profiles\n  FOR UPDATE USING (auth.uid() = id);\n```\n\n‚úÖ **Security Guarantee**: These policies run **at the database level**, enforced by PostgreSQL. Even if an attacker compromises your Next.js API routes, they can't query other users' data.\n\n## ‚è±Ô∏è Part 5: Session & Route Protection\n\n### AuthContext for Global Session State\n\nWe use React Context to provide authentication state throughout the app:\n\n```tsx\n// src/contexts/AuthContext.tsx\n'use client';\n\nimport { createContext, useContext, useEffect, useState } from 'react';\nimport { supabase } from '@/lib/supabase/client';\nimport type { User, Session } from '@supabase/supabase-js';\n\ninterface AuthContextType {\n  user: User | null;\n  session: Session | null;\n  loading: boolean;\n  signOut: () => Promise<void>;\n}\n\nconst AuthContext = createContext<AuthContextType | undefined>(undefined);\n\nexport function AuthProvider({ children }: { children: React.ReactNode }) {\n  const [user, setUser] = useState<User | null>(null);\n  const [session, setSession] = useState<Session | null>(null);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    // Get initial session\n    supabase.auth.getSession().then(({ data: { session } }) => {\n      setSession(session);\n      setUser(session?.user ?? null);\n      setLoading(false);\n    });\n\n    // Listen for auth changes\n    const {\n      data: { subscription },\n    } = supabase.auth.onAuthStateChange((_event, session) => {\n      setSession(session);\n      setUser(session?.user ?? null);\n    });\n\n    return () => subscription.unsubscribe();\n  }, []);\n\n  const signOut = async () => {\n    await supabase.auth.signOut();\n    setSession(null);\n    setUser(null);\n  };\n\n  return (\n    <AuthContext.Provider value={{ user, session, loading, signOut }}>\n      {children}\n    </AuthContext.Provider>\n  );\n}\n\nexport function useAuth() {\n  const context = useContext(AuthContext);\n  if (!context) {\n    throw new Error('useAuth must be used within AuthProvider');\n  }\n  return context;\n}\n```\n\n### Middleware for Protected Routes\n\nNext.js middleware runs before page rendering, making it perfect for authentication checks:\n\n```typescript\n// src/middleware.ts\nimport { type NextRequest } from 'next/server';\nimport { updateSession } from '@/lib/supabase/middleware';\n\nexport async function middleware(request: NextRequest) {\n  return await updateSession(request);\n}\n\nexport const config = {\n  matcher: [\n    '/((?!_next/static|_next/image|favicon.ico|.*\\\\.(?:svg|png|jpg|jpeg|gif|webp)$).*)',\n  ],\n};\n```\n\nThe `updateSession` helper handles session validation and route protection:\n\n```typescript\n// src/lib/supabase/middleware.ts\nimport { createServerClient } from '@supabase/ssr';\nimport { type NextRequest, NextResponse } from 'next/server';\n\nexport async function updateSession(request: NextRequest) {\n  const supabaseResponse = NextResponse.next({ request });\n\n  const supabase = createServerClient(\n    process.env.NEXT_PUBLIC_SUPABASE_URL!,\n    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,\n    {\n      cookies: {\n        getAll() {\n          return request.cookies.getAll();\n        },\n        setAll(cookiesToSet) {\n          cookiesToSet.forEach(({ name, value, options }) => {\n            request.cookies.set(name, value);\n            supabaseResponse.cookies.set(name, value, options);\n          });\n        },\n      },\n    }\n  );\n\n  // Get user session (refreshes expired tokens automatically)\n  const {\n    data: { user },\n  } = await supabase.auth.getUser();\n\n  // Redirect authenticated users away from auth pages\n  if (\n    user &&\n    (request.nextUrl.pathname === '/sign-in' ||\n      request.nextUrl.pathname === '/sign-up')\n  ) {\n    const url = request.nextUrl.clone();\n    url.pathname = '/profile';\n    return NextResponse.redirect(url);\n  }\n\n  // Redirect unauthenticated users from protected routes\n  const protectedRoutes = ['/profile', '/account', '/payment-demo'];\n  if (\n    !user &&\n    protectedRoutes.some((route) => request.nextUrl.pathname.startsWith(route))\n  ) {\n    const url = request.nextUrl.clone();\n    url.pathname = '/sign-in';\n    url.searchParams.set('redirectTo', request.nextUrl.pathname);\n    return NextResponse.redirect(url);\n  }\n\n  return supabaseResponse;\n}\n```\n\nThis middleware pattern ensures:\n\n- Unauthenticated users can't access `/profile`, `/account`, or `/payment-demo`\n- Authenticated users don't see sign-in/sign-up pages (redirected to `/profile`)\n- Session tokens are automatically refreshed before expiration\n\n## üß™ Part 6: Testing Authentication\n\n### Integration Tests with Vitest\n\nWe test authentication flows with real Supabase calls:\n\n```typescript\n// tests/integration/auth/sign-up-flow.test.ts\nimport { describe, it, expect } from 'vitest';\nimport { supabase } from '@/lib/supabase/client';\n\ndescribe('Sign-Up Flow', () => {\n  const testEmail = process.env.TEST_USER_PRIMARY_EMAIL || 'test@example.com';\n  const testPassword =\n    process.env.TEST_USER_PRIMARY_PASSWORD || 'TestPassword123!';\n\n  it('should sign in with valid credentials', async () => {\n    const { data, error } = await supabase.auth.signInWithPassword({\n      email: testEmail,\n      password: testPassword,\n    });\n\n    expect(error).toBeNull();\n    expect(data.user).toBeDefined();\n    expect(data.session).toBeDefined();\n    expect(data.user?.email).toBe(testEmail);\n  });\n\n  it('should reject invalid credentials', async () => {\n    const { data, error } = await supabase.auth.signInWithPassword({\n      email: testEmail,\n      password: 'WrongPassword123!',\n    });\n\n    expect(error).toBeDefined();\n    expect(error?.message).toContain('Invalid login credentials');\n    expect(data.user).toBeNull();\n  });\n});\n```\n\n### E2E Tests with Playwright\n\nEnd-to-End (E2E) tests verify the entire authentication flow in a real browser:\n\n```typescript\n// e2e/auth/sign-in.spec.ts\nimport { test, expect } from '@playwright/test';\n\ntest.describe('Sign-In Flow', () => {\n  test('should sign in successfully with valid credentials', async ({\n    page,\n  }) => {\n    await page.goto('/sign-in');\n\n    // Fill in credentials\n    await page.fill(\n      'input[type=\"email\"]',\n      process.env.TEST_USER_PRIMARY_EMAIL!\n    );\n    await page.fill(\n      'input[type=\"password\"]',\n      process.env.TEST_USER_PRIMARY_PASSWORD!\n    );\n\n    // Submit form\n    await page.click('button[type=\"submit\"]');\n\n    // Should redirect to profile\n    await expect(page).toHaveURL('/profile');\n    await expect(page.getByText('Account Settings')).toBeVisible();\n  });\n\n  test('should show error with invalid credentials', async ({ page }) => {\n    await page.goto('/sign-in');\n\n    await page.fill('input[type=\"email\"]', 'wrong@example.com');\n    await page.fill('input[type=\"password\"]', 'WrongPassword123!');\n    await page.click('button[type=\"submit\"]');\n\n    // Should show error message\n    await expect(page.getByText(/invalid login credentials/i)).toBeVisible();\n  });\n});\n```\n\n## üí° Part 7: What We Learned\n\n### Lesson 1: Cookies vs localStorage\n\nFor static sites with no server-side code exchange, we use `localStorage` for session tokens with Supabase's implicit flow:\n\n```typescript\n// src/lib/supabase/client.ts\nexport function createClient(): SupabaseClient<Database> {\n  const supabaseInstance = createSupabaseClient<Database>(\n    supabaseUrl,\n    supabaseAnonKey,\n    {\n      auth: {\n        // Use implicit flow for static sites (no server-side code exchange)\n        flowType: 'implicit',\n        // Store session in localStorage\n        storage:\n          typeof window !== 'undefined' ? window.localStorage : undefined,\n        autoRefreshToken: true,\n        persistSession: true,\n        detectSessionInUrl: true,\n      },\n    }\n  );\n\n  return supabaseInstance;\n}\n```\n\nFor server-side authentication (SSR), use `@supabase/ssr` with `httpOnly` cookies as shown in the middleware section.\n\n### Lesson 2: Test Isolation & Cleanup\n\nOur tests initially failed because of leftover database state. When testing rate limiting or OAuth flows, **always clean up database records in `beforeEach`**:\n\n```typescript\nbeforeEach(async () => {\n  // Clean up rate limit attempts\n  await supabase\n    .from('rate_limit_attempts')\n    .delete()\n    .eq('identifier', testEmail);\n\n  // Clean up OAuth states\n  await supabase\n    .from('oauth_states')\n    .delete()\n    .neq('id', '00000000-0000-0000-0000-000000000000');\n});\n```\n\n### Lesson 3: Isolate OAuth State\n\nWhen running multiple OAuth tests, shared `localStorage` caused state token collisions. Solution: **use separate storage keys per test client**:\n\n```typescript\nconst userAClient = createClient(supabaseUrl, supabaseAnonKey, {\n  auth: {\n    storageKey: 'test-user-a-session', // Unique per client\n  },\n});\n\nconst userBClient = createClient(supabaseUrl, supabaseAnonKey, {\n  auth: {\n    storageKey: 'test-user-b-session', // Different key\n  },\n});\n```\n\n### Lesson 4: Fail Open on Rate Errors\n\nWhen the rate limit database query fails, **fail open** (allow the request) rather than **fail closed** (block everyone):\n\n```typescript\nexport async function checkRateLimit(...args) {\n  const { data, error } = await supabase.rpc('check_rate_limit', ...);\n\n  if (error) {\n    console.error('Rate limit check failed:', error);\n    // Fail open - allow request rather than blocking everyone\n    return { allowed: true, remaining: 5, locked_until: null };\n  }\n\n  return data;\n}\n```\n\nThis prevents a database outage from locking out all users.\n\n## ‚úÖ Conclusion: Authentication Done Right\n\nBuilding production authentication isn't about copying Auth0's API. It's about understanding the security principles:\n\n1. **Defense in Depth**: Rate limiting in PostgreSQL, RLS policies at database level, CSRF tokens for OAuth\n2. **Fail Safely**: Fail open on errors, provide clear error messages, don't lock out legitimate users\n3. **Test Realistically**: Integration tests with real Supabase, E2E tests in real browsers, database cleanup between tests\n\nThe result? An authentication system that ships to production, passes security audits, and users don't even notice‚Äîbecause it just works.\n\nNext up: [Offline-First Payment System with Stripe and PayPal](/blog/offline-payment-system-stripe-paypal) - how we handle payments on static sites with Supabase Edge Functions.\n\n---\n\n**Want to see the full implementation?** Check out the [ScriptHammer GitHub repository](https://github.com/TortoiseWolfe/ScriptHammer).\n",
      "excerpt": "Secure authentication with Supabase, OAuth providers, server-side rate limiting, and Row-Level Security in Next.js 15 & PostgreSQL.",
      "publishedAt": "2025-10-08T00:00:00.000Z",
      "updatedAt": "2025-10-08T14:56:16.876Z",
      "status": "published",
      "author": {
        "id": "default",
        "name": "TortoiseWolfe"
      },
      "metadata": {
        "tags": [
          "authentication",
          "supabase",
          "oauth",
          "security",
          "next.js",
          "typescript"
        ],
        "categories": [
          "tutorials",
          "security"
        ],
        "readingTime": 17,
        "wordCount": 3391,
        "showToc": true,
        "showAuthor": true,
        "showShareButtons": true,
        "featured": false,
        "featuredImage": "/blog-images/authentication-supabase-oauth/featured-og.svg",
        "featuredImageAlt": "Production-Ready Authentication with Supabase - OAuth, Security Hardening, and PostgreSQL"
      },
      "seo": {
        "title": "Supabase Authentication: OAuth & Security Guide",
        "description": "Secure authentication with Supabase, OAuth providers, server-side rate limiting, and Row-Level Security in Next.js 15 & PostgreSQL.",
        "keywords": [
          "authentication",
          "supabase",
          "oauth",
          "security",
          "next.js",
          "typescript"
        ],
        "ogTitle": "Production-Ready Authentication with Supabase - OAuth & Security",
        "ogDescription": "Complete guide to implementing secure authentication with Supabase, OAuth (GitHub/Google), server-side rate limiting, and Row-Level Security policies.",
        "ogImage": "/blog-images/authentication-supabase-oauth/featured-og.png",
        "twitterCard": "summary_large_image"
      },
      "frontMatter": {
        "title": "Supabase Authentication: OAuth & Security Guide",
        "author": "TortoiseWolfe",
        "date": "2025-10-08T00:00:00.000Z",
        "slug": "authentication-supabase-oauth",
        "tags": [
          "authentication",
          "supabase",
          "oauth",
          "security",
          "next.js",
          "typescript"
        ],
        "categories": [
          "tutorials",
          "security"
        ],
        "excerpt": "Secure authentication with Supabase, OAuth providers, server-side rate limiting, and Row-Level Security in Next.js 15 & PostgreSQL.",
        "featuredImage": "/blog-images/authentication-supabase-oauth/featured-og.svg",
        "featuredImageAlt": "Production-Ready Authentication with Supabase - OAuth, Security Hardening, and PostgreSQL",
        "ogImage": "/blog-images/authentication-supabase-oauth/featured-og.png",
        "ogTitle": "Production-Ready Authentication with Supabase - OAuth & Security",
        "ogDescription": "Complete guide to implementing secure authentication with Supabase, OAuth (GitHub/Google), server-side rate limiting, and Row-Level Security policies.",
        "twitterCard": "summary_large_image"
      }
    },
    {
      "id": "post_b2928454",
      "slug": "countdown-timer-tutorial",
      "title": "Build a Countdown Timer Tutorial",
      "content": "\n# From Template to Client: Building Landing Pages That Convert\n\n## üéØ The Landing Page Strategy\n\nScriptHammer isn't just a Next.js template‚Äîit's your **entry point** to client relationships.\n\n**The Pitch**: \"I'll customize this production-ready template for your domain on GitHub Pages. $321/year. 12 hours of my time annually.\"\n\nThat's **$27/month** for a professional landing page with:\n\n- Theme customization (most brands just pick light/dark, though ScriptHammer includes 32 themes)\n- Progressive Web App (PWA) capabilities (offline support)\n- Contact forms + calendar booking\n- Search Engine Optimization (SEO)-optimized blog\n- Mobile-responsive, accessible\n\n**The Business Model**: 4 hours initial setup + 8 hours quarterly updates = your foot in the door. When they need a Content Management System (CMS), e-commerce, or custom features‚Äîyou're their trusted webmaster with recurring revenue + upsell pipeline.\n\n## ‚è±Ô∏è Why Countdown Timers Work\n\nCountdown timers increase conversions by 8-12%. But fake urgency erodes trust. If you say it ends at midnight January 1st, it **must disappear** at midnight January 1st.\n\nLet's build a real countdown timer using **Product Requirements Prompt (PRP) ‚Üí SpecKit workflow**.\n\n---\n\n# Part 1: The PRP (Product Requirements Prompt)\n\nA Product Requirements Prompt (PRP) focuses on **what users need**, not how to build it. The `/specify` command reads your PRP and searches the codebase to determine technical approach. PRPs have 3 core sections focusing on product requirements:\n\n## üìã 1. Product Requirements\n\n**What**: Countdown banner showing time until January 1st midnight, promoting \"$321/year Custom Setup\", linking to `/schedule`\n\n**Why**: Drive conversions (8-12% boost), demonstrate capability, capture high-intent leads\n\n**Success Criteria**: Accurate to the second, disappears at midnight, tracks dismissals, mobile responsive, accessible, no Server-Side Rendering (SSR) hydration issues\n\n**Out of Scope**: Payment processing, discount codes, email automation, analytics, A/B testing (Minimum Viable Product/MVP)\n\n## üß† 2. Context & Codebase Intelligence\n\n**Reuse Existing**:\n\n- Button component (`@/components/atomic/Button`)\n- Calendar integration (`/schedule` page already exists)\n- Layout file (`src/app/layout.tsx`) - we'll add the banner below the header\n\n**No New Dependencies**: Use native browser Application Programming Interfaces (APIs)\n\n## üî® 3. Implementation Runbook\n\n**SpecKit Workflow** (PRP ‚Üí Spec ‚Üí Plan ‚Üí Tasks ‚Üí Implement):\n\n> **Note for Readers**: Steps 2-4 require [Claude Code CLI](https://claude.com/claude-code) installed and configured. If you don't have Claude Code, skip directly to step 5 (component generation) and follow the code examples in Part 2.\n\n```bash\n# 1. Create feature branch (run from host machine)\n./scripts/prp-to-feature.sh countdown-timer 016\n\n# 2. Generate SpecKit spec (Claude Code slash command - tell Claude in the CLI)\n/specify New Year's countdown banner with $321/year offer\n\n# 3. Generate implementation plan (Claude Code slash command)\n/plan Use native Date, localStorage, integrate into layout\n\n# 4. Generate task list (Claude Code slash command)\n/tasks Focus on Test-Driven Development (TDD) approach\n\n# 5. Generate component scaffold (run in Docker container - interactive prompts)\ndocker compose exec scripthammer pnpm run generate:component\n# You'll be prompted for:\n#   - Component name: CountdownBanner\n#   - Category: atomic\n#   - Has props? Y\n#   - Include hooks? N\n```\n\n<details>\n<summary>‚ñ∂Ô∏è üí° <strong>CLICK HERE: Pro Tip - CLI Arguments for Automation</strong></summary>\n\n**For scripting and automation:**\n\n```bash\ndocker compose exec scripthammer pnpm run generate:component -- \\\n  --name CountdownBanner \\\n  --category atomic \\\n  --hasProps true \\\n  --withHooks false\n```\n\n**Available categories:** `subatomic`, `atomic`, `molecular`, `organisms`, `templates`\n\n</details>\n\n**Generated Artifacts** (if using Claude Code): SpecKit creates `spec.md` (Given/When/Then, Functional Requirements/FR-001+, Non-Functional Requirements/NFR-001+), `plan.md` (technical specs), `research.md`, `data-model.md`, `tasks.md`\n\n**Without Claude Code**: Skip to step 5 and follow the code implementation in Part 2. The component generator creates the 5-file pattern scaffold:\n\n```\nCountdownBanner/\n‚îú‚îÄ‚îÄ index.tsx                             # Barrel export (re-exports component)\n‚îú‚îÄ‚îÄ CountdownBanner.tsx                   # Main component (implement below)\n‚îú‚îÄ‚îÄ CountdownBanner.test.tsx              # Unit tests (see test code below)\n‚îú‚îÄ‚îÄ CountdownBanner.stories.tsx           # Storybook stories (update after implementation)\n‚îî‚îÄ‚îÄ CountdownBanner.accessibility.test.tsx # A11y tests (update after implementation)\n```\n\nThe `index.tsx` barrel export allows you to import with `import { CountdownBanner } from '@/components/atomic/CountdownBanner'` instead of specifying the full file path.\n\n**Note for Storybook**: When creating `CountdownBanner.stories.tsx`, use `@storybook/nextjs` for imports in Next.js projects:\n\n```tsx\nimport type { Meta, StoryObj } from '@storybook/nextjs'; // Not @storybook/react\n```\n\n---\n\n# Part 2: The Code (From SpecKit to Production)\n\nAfter running the SpecKit workflow, `/plan` generates technical specifications like state management, timer logic, and rendering approach. Now we implement:\n\n**Tests** (`CountdownBanner.test.tsx`):\n\n```tsx\nimport { describe, it, expect, vi, beforeEach } from 'vitest';\nimport { render, screen, fireEvent } from '@testing-library/react';\n\n// Mock Next.js router (required for useRouter hook)\nvi.mock('next/navigation', () => ({\n  useRouter: () => ({\n    push: vi.fn(),\n  }),\n}));\n\nimport { CountdownBanner } from './CountdownBanner';\n\ndescribe('CountdownBanner', () => {\n  beforeEach(() => {\n    localStorage.clear();\n  });\n\n  it('renders countdown timer', () => {\n    const { container } = render(<CountdownBanner />);\n    // Verify timer displays format like \"92d 8h 10m 35s\"\n    const timerText = container.textContent;\n    expect(timerText).toMatch(/\\d+d\\s+\\d+h\\s+\\d+m\\s+\\d+s/);\n  });\n\n  it('renders promotional content', () => {\n    render(<CountdownBanner />);\n    expect(screen.getByText('$321/year')).toBeInTheDocument();\n    expect(screen.getByText('Book Now')).toBeInTheDocument();\n  });\n\n  it('persists dismissal with timestamp', () => {\n    render(<CountdownBanner />);\n    const dismissButton = screen.getByLabelText(/dismiss/i);\n    fireEvent.click(dismissButton);\n    const dismissedAt = localStorage.getItem('countdown-dismissed');\n    expect(dismissedAt).toBeTruthy();\n    expect(parseInt(dismissedAt!, 10)).toBeGreaterThan(Date.now() - 1000);\n  });\n});\n```\n\n**Component** (`CountdownBanner.tsx` - full code, inline comments explain key concepts):\n\n```tsx\n'use client';\nimport { useState, useEffect } from 'react';\nimport { useRouter } from 'next/navigation';\nimport Button from '@/components/atomic/Button';\n\nconst DISMISS_KEY = 'countdown-dismissed';\nconst DISMISS_DURATION = 24 * 60 * 60 * 1000; // 24 hours in milliseconds\n\nexport const CountdownBanner = () => {\n  const router = useRouter();\n  const [mounted, setMounted] = useState(false); // Avoid SSR hydration mismatch\n  const [isDismissed, setIsDismissed] = useState(false);\n  const [timeLeft, setTimeLeft] = useState({\n    days: 0,\n    hours: 0,\n    minutes: 0,\n    seconds: 0,\n    isExpired: false,\n  });\n\n  // Check dismissal on mount\n  useEffect(() => {\n    setMounted(true);\n    try {\n      const dismissedAt = localStorage.getItem(DISMISS_KEY);\n      if (dismissedAt) {\n        const timeSinceDismissal = Date.now() - parseInt(dismissedAt, 10);\n        setIsDismissed(timeSinceDismissal < DISMISS_DURATION);\n      }\n    } catch (e) {\n      // Safari private mode - user will see banner every time\n      setIsDismissed(false);\n    }\n  }, []);\n\n  // Calculate and update countdown\n  useEffect(() => {\n    if (!mounted || isDismissed) return;\n\n    const calculateTimeLeft = () => {\n      const targetDate = new Date(new Date().getFullYear() + 1, 0, 1); // Jan 1 local time\n      const difference = targetDate.getTime() - new Date().getTime();\n\n      if (difference <= 0) {\n        return { days: 0, hours: 0, minutes: 0, seconds: 0, isExpired: true };\n      }\n\n      return {\n        days: Math.floor(difference / (1000 * 60 * 60 * 24)),\n        hours: Math.floor((difference / (1000 * 60 * 60)) % 24), // Modulo extracts remainder\n        minutes: Math.floor((difference / 1000 / 60) % 60),\n        seconds: Math.floor((difference / 1000) % 60),\n        isExpired: false,\n      };\n    };\n\n    setTimeLeft(calculateTimeLeft());\n    const timer = setInterval(() => setTimeLeft(calculateTimeLeft()), 1000);\n    return () => clearInterval(timer); // Cleanup prevents memory leaks\n  }, [mounted, isDismissed]);\n\n  if (!mounted || isDismissed || timeLeft.isExpired) return null;\n\n  return (\n    <div\n      className=\"bg-warning text-warning-content fixed top-40 right-4 z-50 max-w-xs rounded-lg p-3 shadow-xl max-sm:top-56 max-sm:right-4 max-sm:left-4 max-sm:max-w-full\"\n      role=\"banner\"\n      aria-live=\"polite\"\n    >\n      <div className=\"flex flex-col gap-3\">\n        <div className=\"flex items-center gap-2\">\n          <span className=\"text-2xl\">‚è∞</span>\n          <div>\n            <span className=\"font-bold\">New Year Special</span>\n            <div className=\"font-mono text-lg\">\n              {timeLeft.days}d {timeLeft.hours}h {timeLeft.minutes}m{' '}\n              {timeLeft.seconds}s\n            </div>\n          </div>\n        </div>\n\n        <div className=\"flex items-center gap-3\">\n          <div className=\"text-center\">\n            <div className=\"text-2xl font-bold\">$321/year</div>\n            <div className=\"text-sm\">Custom ScriptHammer Setup</div>\n          </div>\n          <Button variant=\"accent\" onClick={() => router.push('/schedule')}>\n            Book Now\n          </Button>\n        </div>\n\n        <button\n          className=\"btn btn-sm btn-circle btn-ghost absolute top-2 right-2\"\n          onClick={() => {\n            try {\n              localStorage.setItem(DISMISS_KEY, Date.now().toString());\n              setIsDismissed(true);\n            } catch (e) {\n              // Safari private mode - just hide for session\n              setIsDismissed(true);\n            }\n          }}\n          aria-label=\"Dismiss countdown banner\"\n        >\n          ‚úï\n        </button>\n      </div>\n    </div>\n  );\n};\n```\n\n> **UI Layout Note**: The banner uses `top-40 right-4` to stack vertically below blog SEO/TOC controls (at `top-20 right-4`), preventing overlap. All UI elements align to the right edge with clear hierarchy: functional controls ‚Üí promotional content.\n\n**Integration** (`src/app/layout.tsx`):\n\n```tsx\nimport { CountdownBanner } from '@/components/atomic/CountdownBanner';\nimport { GlobalNav } from '@/components/GlobalNav';\nimport { Footer } from '@/components/Footer';\n\nexport default function RootLayout({ children }) {\n  return (\n    <html>\n      <body>\n        <GlobalNav />\n        <CountdownBanner /> {/* Appears on all pages */}\n        <main>{children}</main>\n        <Footer />\n      </body>\n    </html>\n  );\n}\n```\n\n**Validation**:\n\n```bash\n# Format code to match project style\ndocker compose exec scripthammer pnpm run format\n\n# Run full test suite and build\ndocker compose exec scripthammer sh -c \"pnpm run test:suite && pnpm run build\"\n```\n\n---\n\n# Part 3: Validation & Next Steps\n\n**Validation**: Test-Driven Development (TDD) (tests first), 5-file pattern, mobile tested, accessibility verified, cross-browser, Lighthouse check\n\n**Key Technical Considerations** (from `/plan`):\n\n- **Timezone**: Use `new Date(year + 1, 0, 1)` (local) not UTC string\n- **SSR Mismatch**: Don't render until `mounted` (see code)\n- **Memory Leak**: Return `() => clearInterval(timer)` in useEffect\n- **localStorage**: Wrap in try/catch for Safari private mode\n\n**References**: PRP Methodology (`docs/prp-docs/`), SpecKit Guide, Component Generator, React docs, MDN (localStorage, ARIA)\n\n---\n\n# What You've Learned\n\n**Technical**: React hooks, TypeScript, TDD, responsive design, Web Application Programming Interfaces (APIs) (localStorage, Date, setInterval)\n\n**Process**: PRP methodology, SpecKit workflow (/specify ‚Üí /plan ‚Üí /tasks ‚Üí /implement), 5-file component pattern\n\n**Business**: $321/year landing page service, conversion optimization, sales funnel, recurring revenue\n\n## üöÄ Next Steps\n\n**Customize**: Edit price, CTA text, target date in code\n\n**Test**: `docker compose exec scripthammer sh -c \"pnpm run test:suite && pnpm run build\"`\n\n**Deploy**: `git add . && git commit -m \"feat: Countdown banner\" && git push` (GitHub Actions auto-deploys)\n\n**Track**: Add Google Analytics events, monitor click-through rate, A/B test CTA variations\n\n**Iterate**: Test different CTA text, add social proof, consider exit-intent popup\n\n---\n\n## üí° The Bigger Picture\n\nThis tutorial demonstrates **building a consulting business** using ScriptHammer:\n\n**Your Stack**: Template + Blog + Storybook + Calendar + Contact Form = Portfolio\n\n**Your Process**: PRP ‚Üí SpecKit = Documented, repeatable, quality-assured workflow\n\n**Your Offer**: $321/year entry point ‚Üí Value ladder ‚Üí Recurring revenue\n\nClients want proven solutions. Developers want starting points. Consultants want leverage. ScriptHammer gives you all three.\n\n---\n\n## ‚úÖ Ready to Start?\n\n‚úÖ Production-ready countdown component\n‚úÖ Repeatable PRP/SpecKit workflow\n‚úÖ Business model for consulting\n‚úÖ Template to showcase capabilities\n\n**Next Move**: [Fork ScriptHammer](https://github.com/TortoiseWolfe/ScriptHammer/fork) ‚Üí Deploy countdown ‚Üí Share on LinkedIn ‚Üí Book first client\n\n---\n\n_This tutorial was written using the PRP/SpecKit methodology it teaches._\n",
      "excerpt": "Learn the PRP/SpecKit workflow by building a countdown timer. From requirements to production code with ScriptHammer template.",
      "publishedAt": "2025-09-30T00:00:00.000Z",
      "updatedAt": "2025-10-08T00:24:43.499Z",
      "status": "published",
      "author": {
        "id": "default",
        "name": "TortoiseWolfe"
      },
      "metadata": {
        "tags": [
          "tutorial",
          "prp-workflow",
          "react",
          "typescript",
          "component-development",
          "conversion-optimization",
          "business-strategy"
        ],
        "categories": [
          "tutorial",
          "business"
        ],
        "readingTime": 9,
        "wordCount": 1645,
        "showToc": true,
        "showAuthor": true,
        "showShareButtons": true,
        "featured": false,
        "featuredImage": "/blog-images/countdown-timer-tutorial/countdown-banner-preview.svg",
        "featuredImageAlt": "Countdown timer component showing days, hours, minutes, seconds with New Year sale promotion"
      },
      "seo": {
        "title": "Build a Countdown Timer Tutorial",
        "description": "Learn the PRP/SpecKit workflow by building a countdown timer. From requirements to production code with ScriptHammer template.",
        "keywords": [
          "tutorial",
          "prp-workflow",
          "react",
          "typescript",
          "component-development",
          "conversion-optimization",
          "business-strategy"
        ],
        "ogTitle": "Build a Countdown Timer - PRP/SpecKit Tutorial",
        "ogDescription": "Learn the PRP/SpecKit workflow by building a countdown timer. Step-by-step tutorial from requirements to production-ready code with ScriptHammer.",
        "ogImage": "/blog-images/countdown-timer-tutorial/countdown-banner-og.png",
        "twitterCard": "summary_large_image"
      },
      "frontMatter": {
        "title": "Build a Countdown Timer Tutorial",
        "author": "TortoiseWolfe",
        "date": "2025-09-30T00:00:00.000Z",
        "slug": "countdown-timer-tutorial",
        "tags": [
          "tutorial",
          "prp-workflow",
          "react",
          "typescript",
          "component-development",
          "conversion-optimization",
          "business-strategy"
        ],
        "categories": [
          "tutorial",
          "business"
        ],
        "excerpt": "Learn the PRP/SpecKit workflow by building a countdown timer. From requirements to production code with ScriptHammer template.",
        "featuredImage": "/blog-images/countdown-timer-tutorial/countdown-banner-preview.svg",
        "featuredImageAlt": "Countdown timer component showing days, hours, minutes, seconds with New Year sale promotion",
        "ogImage": "/blog-images/countdown-timer-tutorial/countdown-banner-og.png",
        "ogTitle": "Build a Countdown Timer - PRP/SpecKit Tutorial",
        "ogDescription": "Learn the PRP/SpecKit workflow by building a countdown timer. Step-by-step tutorial from requirements to production-ready code with ScriptHammer.",
        "twitterCard": "summary_large_image",
        "linkedinAuthorUrl": "https://www.linkedin.com/in/pohlner/"
      }
    },
    {
      "id": "post_7db0888d",
      "slug": "this-is-an-extremely-long-url-slug-that-should-be-much-shorter-for-better-seo",
      "title": "low seo",
      "content": "\n## ‚ö†Ô∏è Bad SEO Example\n\nThis is a blog post about something that I wanted to write about but I'm not going to include any structure or optimization whatsoever because this is meant to be a bad example that triggers all the SEO warnings in our analyzer system which is designed to help users write better content by identifying common SEO issues that can negatively impact search engine rankings and user engagement metrics.\n\nThis entire paragraph is just one long run-on sentence without any breaks or structure which makes it very difficult to read and understand what the main point is supposed to be and there are no headings or subheadings to break up the content into digestible sections.\n\nThere are no images to make the content more visually appealing and engaging for readers who might otherwise get bored reading a wall of text like this one that just goes on and on without any clear purpose or direction.\n\nThe content is also very short overall and doesn't provide enough information to be valuable to readers or search engines that are looking for comprehensive authoritative content on a topic and there are no keywords or tags defined to help search engines understand what this content is about and there's no meta description that would appear in search results to entice users to click through to read the full article and without any links to other resources or related content this post exists in isolation without contributing to or benefiting from the broader link structure of the website.\n",
      "excerpt": "This is a blog post",
      "publishedAt": "2025-09-28T00:00:00.000Z",
      "updatedAt": "2025-10-08T01:23:09.602Z",
      "status": "published",
      "author": {
        "id": "default",
        "name": "Anonymous"
      },
      "metadata": {
        "tags": [
          "seo",
          "optimization",
          "content-writing",
          "best-practices",
          "web-development"
        ],
        "categories": [],
        "readingTime": 2,
        "wordCount": 257,
        "showToc": true,
        "showAuthor": true,
        "showShareButtons": true,
        "featured": false
      },
      "seo": {
        "title": "low seo",
        "description": "This is a blog post",
        "keywords": [
          "seo",
          "optimization",
          "content-writing",
          "best-practices",
          "web-development"
        ],
        "ogTitle": "low seo",
        "ogDescription": "This is a blog post",
        "ogImage": "/blog-images/bad-seo-example-og.png",
        "twitterCard": "summary"
      },
      "frontMatter": {
        "title": "low seo",
        "author": "Anonymous",
        "date": "2025-09-28T00:00:00.000Z",
        "slug": "this-is-an-extremely-long-url-slug-that-should-be-much-shorter-for-better-seo",
        "excerpt": "This is a blog post",
        "ogImage": "/blog-images/bad-seo-example-og.png",
        "tags": [
          "seo",
          "optimization",
          "content-writing",
          "best-practices",
          "web-development"
        ]
      }
    },
    {
      "id": "post_5ec10b04",
      "slug": "auto-configuration-system",
      "title": "Auto-Configuration: Use Template and Start Building",
      "content": "\n# Auto-Configuration: Use Template and Start Building\n\nScriptHammer automatically configures itself based on your new repository. Use this template, and everything adapts to your project name and settings with minimal setup.\n\n## ‚úÖ Prerequisites\n\n- **Docker and Docker Compose installed (MANDATORY)**\n- Git configured with a remote repository\n- Basic familiarity with terminal commands\n\n**‚ö†Ô∏è IMPORTANT**: This project REQUIRES Docker. Local npm/pnpm commands are NOT supported. All development MUST use Docker containers.\n\n## üöÄ Quick Start (10-15 min)\n\n### 1. Use Template on GitHub\n\nClick \"Use this template\" on [ScriptHammer](https://github.com/TortoiseWolfe/ScriptHammer) and create your repository with any name you like.\n\n### 2. Clone Your New Repository\n\n```bash\ngit clone https://github.com/YourUsername/your-new-repo.git\ncd your-new-repo\n```\n\n### 3. Create and Configure .env File\n\n**IMPORTANT**: This step is required for Docker to run with proper permissions.\n\nFirst, check your User ID and Group ID:\n\n```bash\nid -u  # Shows your UID (often 1000)\nid -g  # Shows your GID (often 1000)\n```\n\nThen create your .env file:\n\n```bash\n# Copy the example file (contains all available options)\ncp .env.example .env\n```\n\nNow **EDIT the .env file** to add your configuration:\n\n```bash\n# Required for Docker - check your actual values:\n# Run: id -u  (to get your UID)\n# Run: id -g  (to get your GID)\nUID=1000  # Replace if your 'id -u' shows different\nGID=1000  # Replace if your 'id -g' shows different\n\n# Optional - Add your service credentials:\nNEXT_PUBLIC_GA_MEASUREMENT_ID=G-XXXXXXXXXX        # Google Analytics\nNEXT_PUBLIC_WEB3FORMS_ACCESS_KEY=your-key-here    # Contact form\nNEXT_PUBLIC_EMAILJS_SERVICE_ID=service_xxx        # Email service\nNEXT_PUBLIC_CALENDAR_URL=your-calendly-url        # Scheduling\n\n# Optional - Customize author info:\nNEXT_PUBLIC_AUTHOR_NAME=Your Name\nNEXT_PUBLIC_AUTHOR_GITHUB=yourusername\nNEXT_PUBLIC_AUTHOR_TWITTER=yourhandle\n```\n\n**Note**: All these are OPTIONAL except UID/GID. The app works without them, but features like analytics and contact forms won't function until configured.\n\n### 4. Start Docker (MANDATORY)\n\n```bash\ndocker compose up\n```\n\nNote: First run will take 5-10 minutes to build the Docker image and install dependencies.\n\n**‚ö†Ô∏è DO NOT attempt to run `npm install` or `pnpm install` locally - it WILL NOT WORK.**\n\n### 5. Access Your Project\n\nYour project is now running at `http://localhost:3000` with your repository name automatically detected!\n\nAll commands MUST be run inside Docker:\n\n```bash\n# ‚ùå WRONG: pnpm run dev\n# ‚úÖ RIGHT: docker compose exec scripthammer pnpm run dev\n```\n\n## üîß What Gets Auto-Configured\n\nWhen you create from template and clone, ScriptHammer automatically detects and configures:\n\n- **Project Name**: From your repository name\n- **Owner Info**: From your GitHub username (not \"Admin\" or generic names)\n- **Author Attribution**: Your actual GitHub username appears everywhere\n- **URLs**: For deployment and links\n- **PWA Settings**: App name and manifest\n- **Build Paths**: For GitHub Pages deployment\n\n### Where to Find Your Configuration\n\nThe auto-config system generates configuration at build time:\n\n1. **TypeScript Config**: `/src/config/project-detected.ts` - Strongly typed for your components\n2. **JSON Config**: `/src/config/project-detected.json` - Raw configuration data\n\nCheck these files after running `docker compose exec scripthammer pnpm run build` - they contain YOUR project's information automatically detected from Git.\n\n## üí° How to Use It\n\nThe configuration is available everywhere in your code:\n\n```typescript\n// In any component\nimport { detectedConfig } from '@/config/project-detected';\n\nexport function Header() {\n  return (\n    <div>\n      <h1>{detectedConfig.projectName}</h1>\n      <a href={detectedConfig.projectUrl}>View on GitHub</a>\n    </div>\n  );\n}\n```\n\n```typescript\n// In API routes\nimport { detectedConfig } from '@/config/project-detected';\n\nexport async function GET() {\n  return Response.json({\n    project: detectedConfig.projectName,\n    owner: detectedConfig.projectOwner,\n  });\n}\n```\n\n## ‚öôÔ∏è Minimal Manual Setup\n\nTraditional templates require editing multiple files:\n\n- ‚ùå Update package.json with project name\n- ‚ùå Change configuration files in multiple locations\n- ‚ùå Modify deployment scripts\n- ‚ùå Edit PWA manifests\n- ‚ùå Update hardcoded references throughout codebase\n\nWith ScriptHammer, the process is dramatically simplified:\n\n- ‚úÖ Use template with any name\n- ‚úÖ Create `.env` file (one-time, 30 seconds)\n- ‚úÖ Most configuration detected automatically from git\n- ‚ö†Ô∏è Some components may still have hardcoded values (being improved)\n\n## üõ†Ô∏è Common Tasks (All Require Docker)\n\n### Deploy to GitHub Pages\n\n```bash\n# MUST use Docker - local commands won't work\ndocker compose exec scripthammer pnpm run build\ndocker compose exec scripthammer pnpm run deploy\n# Automatically configured for your repository\n```\n\n### Configure Production Env Vars\n\n**IMPORTANT**: Your local `.env` file is NOT used in GitHub Actions. You must add your configuration as GitHub Secrets for production features to work.\n\n#### Setting Up GitHub Secrets\n\n1. **Navigate to your repository settings**:\n   - Go to your GitHub repository\n   - Click **Settings** ‚Üí **Secrets and variables** ‚Üí **Actions**\n   - Click **New repository secret**\n\n2. **Add your environment variables as secrets**:\n\n   Copy each value from your `.env` file and add it as a GitHub Secret with the SAME name:\n\n   ```bash\n   # All NEXT_PUBLIC_ variables in alphabetical order:\n   NEXT_PUBLIC_AUTHOR_AVATAR           # Avatar image URL\n   NEXT_PUBLIC_AUTHOR_BIO              # Short biography\n   NEXT_PUBLIC_AUTHOR_BLUESKY          # Bluesky handle\n   NEXT_PUBLIC_AUTHOR_EMAIL            # Contact email\n   NEXT_PUBLIC_AUTHOR_GITHUB           # Your GitHub username\n   NEXT_PUBLIC_AUTHOR_LINKEDIN         # Your LinkedIn username\n   NEXT_PUBLIC_AUTHOR_MASTODON         # Mastodon handle (with instance)\n   NEXT_PUBLIC_AUTHOR_NAME             # Your display name\n   NEXT_PUBLIC_AUTHOR_ROLE             # Your professional role/title\n   NEXT_PUBLIC_AUTHOR_TWITCH           # Twitch username\n   NEXT_PUBLIC_AUTHOR_TWITTER          # Your Twitter/X handle\n   NEXT_PUBLIC_AUTHOR_WEBSITE          # Your personal website\n   NEXT_PUBLIC_BASE_PATH               # Override deployment base path\n   NEXT_PUBLIC_BASE_URL                # Base URL for your site\n   NEXT_PUBLIC_CALENDAR_PROVIDER        # 'calendly' or 'calcom'\n   NEXT_PUBLIC_CALENDAR_URL             # Your booking page URL\n   NEXT_PUBLIC_DISQUS_SHORTNAME        # Disqus comments for blog posts\n   NEXT_PUBLIC_EMAILJS_PUBLIC_KEY       # EmailJS public key\n   NEXT_PUBLIC_EMAILJS_SERVICE_ID       # Email service (EmailJS alternative)\n   NEXT_PUBLIC_EMAILJS_TEMPLATE_ID      # Email template ID\n   NEXT_PUBLIC_GA_MEASUREMENT_ID        # Google Analytics tracking\n   NEXT_PUBLIC_GOOGLE_SITE_VERIFICATION # Google Search Console verification\n   NEXT_PUBLIC_PROJECT_NAME            # Override auto-detected project name\n   NEXT_PUBLIC_PROJECT_OWNER           # Override auto-detected owner\n   NEXT_PUBLIC_SITE_TWITTER_HANDLE      # Site-wide Twitter handle for social cards\n   NEXT_PUBLIC_SITE_URL                # Custom domain (if not GitHub Pages)\n   NEXT_PUBLIC_SOCIAL_PLATFORMS        # Comma-separated list of enabled platforms\n   NEXT_PUBLIC_WEB3FORMS_ACCESS_KEY     # Contact form submissions (Web3Forms)\n   ```\n\n3. **How to add a secret**:\n   - **Name**: Enter the exact variable name (e.g., `NEXT_PUBLIC_GA_MEASUREMENT_ID`)\n   - **Value**: Paste your key/value from `.env` (e.g., `G-XXXXXXXXXX`)\n   - Click **Add secret**\n\n4. **Verify secrets are configured**:\n   - After adding, you'll see them listed (values are hidden)\n   - The deploy workflow will automatically use these during build\n   - Check your deployed site to confirm features are working\n\n#### Important Notes\n\n- **No UID/GID needed**: GitHub Actions doesn't need Docker user permissions\n- **Secrets are encrypted**: GitHub encrypts and hides secret values\n- **Build-time injection**: Secrets are injected during `pnpm run build` in CI/CD\n- **Without secrets**: Your site will deploy but features like analytics, forms, and calendars won't function\n\n#### Update Deploy Workflow (Optional)\n\nIf you need to use additional environment variables, update `.github/workflows/deploy.yml`:\n\n```yaml\n- name: Build Next.js app\n  run: pnpm run build\n  env:\n    NEXT_PUBLIC_AUTHOR_AVATAR: ${{ secrets.NEXT_PUBLIC_AUTHOR_AVATAR }}\n    NEXT_PUBLIC_AUTHOR_BIO: ${{ secrets.NEXT_PUBLIC_AUTHOR_BIO }}\n    NEXT_PUBLIC_AUTHOR_BLUESKY: ${{ secrets.NEXT_PUBLIC_AUTHOR_BLUESKY }}\n    NEXT_PUBLIC_AUTHOR_EMAIL: ${{ secrets.NEXT_PUBLIC_AUTHOR_EMAIL }}\n    NEXT_PUBLIC_AUTHOR_GITHUB: ${{ secrets.NEXT_PUBLIC_AUTHOR_GITHUB }}\n    NEXT_PUBLIC_AUTHOR_LINKEDIN: ${{ secrets.NEXT_PUBLIC_AUTHOR_LINKEDIN }}\n    NEXT_PUBLIC_AUTHOR_MASTODON: ${{ secrets.NEXT_PUBLIC_AUTHOR_MASTODON }}\n    NEXT_PUBLIC_AUTHOR_NAME: ${{ secrets.NEXT_PUBLIC_AUTHOR_NAME }}\n    NEXT_PUBLIC_AUTHOR_ROLE: ${{ secrets.NEXT_PUBLIC_AUTHOR_ROLE }}\n    NEXT_PUBLIC_AUTHOR_TWITCH: ${{ secrets.NEXT_PUBLIC_AUTHOR_TWITCH }}\n    NEXT_PUBLIC_AUTHOR_TWITTER: ${{ secrets.NEXT_PUBLIC_AUTHOR_TWITTER }}\n    NEXT_PUBLIC_AUTHOR_WEBSITE: ${{ secrets.NEXT_PUBLIC_AUTHOR_WEBSITE }}\n    # ... all other variables in alphabetical order\n```\n\n**Note**: The current workflow doesn't explicitly list env variables, but Next.js automatically reads `NEXT_PUBLIC_*` secrets during build if they're available in the GitHub Actions environment.\n\n### Run Tests Inside Docker\n\n```bash\n# Run the comprehensive test suite (all tests must run in Docker)\ndocker compose exec scripthammer pnpm run test:suite\n```\n\n**‚ö†Ô∏è REMINDER**: Every single command in this project MUST be prefixed with `docker compose exec scripthammer`. There are NO exceptions.\n\n### Check Current Config\n\nLook at `src/config/project-detected.ts` after running the build‚Äîit shows your detected settings.\n\n## üéØ Key Benefits\n\n- **Quick Setup**: Use template and start coding in 10-15 minutes\n- **Minimal Configuration**: Only `.env` file required, rest auto-detects\n- **Works in Most Environments**: Local Docker, GitHub Actions CI/CD\n- **Reduced Errors**: Fewer manual edits means fewer mistakes\n\n## üîç How It Works\n\nThe core detection script (`scripts/detect-project.js`) runs at build time:\n\n```javascript\nfunction getProjectInfo() {\n  // 1. Check environment variables (highest priority)\n  if (\n    process.env.NEXT_PUBLIC_PROJECT_NAME &&\n    process.env.NEXT_PUBLIC_PROJECT_OWNER\n  ) {\n    return {\n      projectName: process.env.NEXT_PUBLIC_PROJECT_NAME,\n      projectOwner: process.env.NEXT_PUBLIC_PROJECT_OWNER,\n      source: 'env',\n    };\n  }\n\n  // 2. Try git remote detection\n  const gitUrl = getGitRemoteUrl();\n  const gitInfo = parseGitUrl(gitUrl);\n  if (gitInfo) {\n    return {\n      projectName: gitInfo.repo,\n      projectOwner: gitInfo.owner,\n      source: 'git',\n    };\n  }\n\n  // 3. Fall back to defaults\n  return {\n    projectName: 'ScriptHammer',\n    projectOwner: 'TortoiseWolfe',\n    source: 'default',\n  };\n}\n```\n\nThe script (under 180 lines) handles:\n\n- Multiple git remote formats (HTTPS, SSH, various hosts)\n- CI/CD environment detection\n- Safe file writing with atomic operations\n- TypeScript and JSON generation\n\n## üöÄ Advanced Features\n\n### Environment Detection\n\nCurrently supported:\n\n- **GitHub Actions CI** - Automatically configures for GitHub Pages\n- **Docker Development** - Consistent development environment (REQUIRED)\n- **Environment Variables** - Override auto-detection with custom values\n\n### Development vs Production\n\n```bash\n# Development - Local testing with hot reload at http://localhost:3000\ndocker compose exec scripthammer pnpm run dev\n\n# Production Build - Creates static files for GitHub Pages deployment\ndocker compose exec scripthammer pnpm run build\ndocker compose exec scripthammer pnpm run deploy\n```\n\nThe project auto-detects your configuration from git, so you don't need different settings for different environments.\n\n## üß™ Try It Now\n\n1. **Use Template** [ScriptHammer](https://github.com/TortoiseWolfe/ScriptHammer) (30 seconds)\n2. **Clone** your new repository (30 seconds)\n3. **Create .env** with `cp .env.example .env` (30 seconds)\n4. **Run** `docker compose up` (5-10 minutes first build)\n5. **Check** `http://localhost:3000` - your project is ready!\n\n### What You'll See\n\n- Title bar shows YOUR project name\n- Footer links to YOUR GitHub repository\n- PWA installer shows YOUR app name\n- `/status` page displays YOUR project info\n- All configuration files have YOUR details\n\n## üìö Technical Details\n\n### Generated Files\n\nConfiguration files are generated at build time (not committed to git):\n\n- `src/config/project-detected.ts` - TypeScript configuration\n- `src/config/project-detected.json` - JSON for build scripts\n- `public/manifest.json` - PWA manifest with your project name\n- Meta tags and URLs throughout the application\n\n### Git Remote Parsing\n\nSupports multiple formats:\n\n- `https://github.com/user/repo.git`\n- `git@github.com:user/repo.git`\n- `https://gitlab.com/user/repo.git`\n- `git@bitbucket.org:user/repo.git`\n\n### Build Integration\n\n```json\n// package.json\n{\n  \"scripts\": {\n    \"dev\": \"node scripts/detect-project.js && next dev\",\n    \"build\": \"node scripts/detect-project.js && next build\"\n  }\n}\n```\n\n## Visual Overview\n\n![Auto-Configuration Flow Diagram](/blog-images/auto-config/config-flow.svg)\n_The auto-configuration process: Use Template ‚Üí Clone ‚Üí Ready in 3 simple steps_\n\nThe magic happens through our detection script that runs at build time, analyzing your git remote to extract project information and automatically generating all configuration files.\n\n## Traditional Setup vs ScriptHammer\n\n![Before and After Comparison](/blog-images/auto-config/before-after.svg)\n_Save 30-60 minutes of manual configuration with every new project_\n\nWhile traditional templates require editing 22+ files and configuration points, ScriptHammer handles everything automatically. No more hunting for hardcoded values or broken references after using the template.\n\n## ‚ö†Ô∏è Troubleshooting\n\n### Common Issues\n\n**Docker permission errors:**\n\n- Make sure your `.env` file contains correct UID/GID values\n- Run `id -u` and `id -g` to get your system values\n- Ensure Docker daemon is running\n\n**Auto-detection not working:**\n\n- Verify you have a git remote: `git remote -v`\n- If no remote, add one: `git remote add origin https://github.com/YourUsername/your-repo.git`\n- The detection reads from git remote origin URL\n\n**Project name not updating:**\n\n- Auto-detection runs at BUILD time, not runtime\n- Run `docker compose exec scripthammer pnpm run build` to regenerate\n- Check `src/config/project-detected.ts` for detected values\n\n**Hardcoded values still showing \"ScriptHammer\":**\n\n- Some components may still have hardcoded values\n- This is a known limitation being addressed\n- Main configuration files ARE auto-detected correctly\n\n## ‚úÖ The Bottom Line\n\nScriptHammer significantly reduces setup friction compared to traditional templates. While not completely \"zero-config,\" it automates most configuration through git detection, requiring only minimal setup (creating the `.env` file).\n\n**Minimal configuration. Quick setup. Use template and build.**\n\n---\n\n_P.S. - Check out `/scripts/detect-project.js` to see the complete auto-configuration implementation. It's a pragmatic solution that handles 90% of configuration automatically._\n",
      "excerpt": "ScriptHammer's auto-configuration eliminates setup friction. Use the template, run Docker, and watch your project automatically adapt with zero manual config.",
      "publishedAt": "2025-09-27T00:00:00.000Z",
      "updatedAt": "2025-10-08T01:10:36.144Z",
      "status": "published",
      "author": {
        "id": "default",
        "name": "Development Team"
      },
      "metadata": {
        "tags": [
          "auto-config",
          "automation",
          "developer-experience"
        ],
        "categories": [
          "DevOps",
          "Automation",
          "DX"
        ],
        "readingTime": 10,
        "wordCount": 1925,
        "showToc": true,
        "showAuthor": true,
        "showShareButtons": true,
        "featured": true,
        "featuredImage": "/blog-images/auto-config/featured.svg",
        "featuredImageAlt": "Auto-Configuration System - Zero Config Magic for Your New Project"
      },
      "seo": {
        "title": "Auto-Configuration: Use Template and Start Building",
        "description": "ScriptHammer's auto-configuration eliminates setup friction. Use the template, run Docker, and watch your project automatically adapt with zero manual config.",
        "keywords": [
          "auto-config",
          "automation",
          "developer-experience"
        ],
        "ogTitle": "Auto-Configuration: Use Template and Start Building",
        "ogDescription": "ScriptHammer's auto-configuration eliminates setup friction. Use the template, run Docker, and watch your project automatically adapt with zero manual config.",
        "ogImage": "/blog-images/auto-config/featured-og.png",
        "twitterCard": "summary"
      },
      "frontMatter": {
        "title": "Auto-Configuration: Use Template and Start Building",
        "slug": "auto-configuration-system",
        "excerpt": "ScriptHammer's auto-configuration eliminates setup friction. Use the template, run Docker, and watch your project automatically adapt with zero manual config.",
        "author": "Development Team",
        "date": "2025-09-27T00:00:00.000Z",
        "status": "scheduled",
        "featured": true,
        "categories": [
          "DevOps",
          "Automation",
          "DX"
        ],
        "tags": [
          "auto-config",
          "automation",
          "developer-experience"
        ],
        "readTime": "5 min read",
        "featuredImage": "/blog-images/auto-config/featured.svg",
        "featuredImageAlt": "Auto-Configuration System - Zero Config Magic for Your New Project",
        "ogImage": "/blog-images/auto-config/featured-og.png"
      }
    },
    {
      "id": "post_5cf9e78e",
      "slug": "scripthammer-intro",
      "title": "Scripthammer - Opinionated Next.js PWA Template",
      "content": "\n# Scripthammer: Your Production-Ready Next.js Template\n\nScripthammer is an opinionated Next.js template that comes batteries-included with everything you need to build modern web applications. No more setup fatigue - just clone and start building.\n\n## üì¶ What's Actually In This Template\n\n![Scripthammer Dashboard](/blog-images/scripthammer-intro/dashboard-overview.svg)\n_The Scripthammer dashboard showing the theme switcher and component structure_\n\n### üîß Core Technologies\n\n- **[Next.js](https://nextjs.org/) 15.5.2** with App Router and static export support\n- **[React](https://react.dev/) 19.1.0** with [TypeScript](https://www.typescriptlang.org/) strict mode\n- **[Tailwind CSS](https://tailwindcss.com/) (Cascading Style Sheets) v4** with [DaisyUI](https://daisyui.com/) providing 32 built-in themes\n- **PWA Support** with offline capabilities via [Workbox](https://developer.chrome.com/docs/workbox/)\n- **[Docker](https://www.docker.com/)-First Development** - everything runs in containers\n\n### ‚ú® Real Features That Work\n\n#### üé® 32 Theme System\n\nNot just light and dark mode - we ship with 32 complete themes from [DaisyUI](https://daisyui.com/):\n\n- Classic: light, dark, cupcake, bumblebee\n- Modern: synthwave, cyberpunk, valentine, halloween\n- Professional: corporate, business, emerald, forest\n- Experimental: acid, lemonade, coffee, winter\n\nTheme switching is instant and persisted across sessions.\n\n#### ‚ôø Accessibility Built-In\n\n- Color vision assistance for 8 types of color blindness\n- Font size scaling system\n- Screen reader optimizations\n- Keyboard navigation throughout\n- WCAG (Web Content Accessibility Guidelines) 2.1 AA compliance ready\n\n#### üß™ Testing That Actually Runs\n\n![Testing Suite Output](/blog-images/scripthammer-intro/testing-output.svg)\n_Comprehensive test suite with unit, E2E (End-to-End), and accessibility testing_\n\n```bash\ndocker compose exec scripthammer pnpm run test:suite\n```\n\n- [Vitest](https://vitest.dev/) for unit tests (58% coverage)\n- [Playwright](https://playwright.dev/) for E2E (End-to-End) testing (40+ tests)\n- [Pa11y](https://pa11y.org/) for accessibility testing\n- Component structure validation\n- Pre-push hooks with [Husky](https://typicode.github.io/husky/)\n\n#### üì± True PWA Support\n\n- Service worker with offline mode\n- Background sync for form submissions\n- [IndexedDB](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API) for local data storage\n- App manifest for installability\n- Push notification ready\n\n## üê≥ Docker Development Environment (MANDATORY)\n\n![Docker Architecture](/blog-images/scripthammer-intro/docker-architecture.svg)\n_Docker-first development environment with isolated containers_\n\n**‚ö†Ô∏è CRITICAL**: ScriptHammer is Docker-only. Local npm/pnpm commands are NOT supported and WILL NOT WORK.\n\nEverything MUST run in [Docker](https://www.docker.com/). No \"works on my machine\" problems:\n\n```bash\n# Start development (REQUIRED - no local alternative)\ndocker compose up\n\n# ALL commands must use docker compose exec:\ndocker compose exec scripthammer pnpm run dev\ndocker compose exec scripthammer pnpm test\ndocker compose exec scripthammer pnpm run generate:component\n\n# ‚ùå NEVER run locally:\n# pnpm install  # WILL NOT WORK\n# npm run dev   # WILL NOT WORK\n```\n\n## üî® Component Generator\n\nStop copying component boilerplate. Use the generator:\n\n```bash\ndocker compose exec scripthammer pnpm run generate:component MyComponent atomic\n```\n\nThis creates the required 5-file structure:\n\n- `MyComponent.tsx` - Main component\n- `MyComponent.test.tsx` - Unit tests\n- `MyComponent.stories.tsx` - [Storybook](https://storybook.js.org/) stories\n- `MyComponent.accessibility.test.tsx` - A11y tests\n- `index.tsx` - Barrel export\n\n## ‚öôÔ∏è Project Configuration\n\nThe project auto-detects most configuration from your Git repository:\n\n```typescript\n// Auto-configured from git remote at build time\nconst projectConfig = {\n  name: 'YourRepoName', // Detected from repository\n  owner: 'YourGitHubUsername',\n  basePath: '/', // Configured for GitHub Pages\n  repository: 'https://github.com/YourUsername/YourRepoName',\n};\n```\n\nMinimal setup required - just create your `.env` file and the rest is detected automatically.\n\n## üöÄ Current Features in Production\n\n### üîí Privacy & Consent\n\n- GDPR (General Data Protection Regulation)-compliant cookie consent system\n- Granular privacy controls\n- [Google Analytics](https://analytics.google.com/) integration (with consent)\n\n### üìù Blog System\n\n- Markdown-based blog with frontmatter\n- SEO (Search Engine Optimization) analysis and scoring\n- Table of contents generation\n- Offline-first with IndexedDB storage\n- Background sync for offline edits\n\n### üó∫Ô∏è Maps & Location\n\n- [Leaflet](https://leafletjs.com/) integration for interactive maps\n- Geolocation with privacy consent\n- [OpenStreetMap](https://www.openstreetmap.org/) tiles (no API (Application Programming Interface) key needed)\n\n### üìÖ Calendar Integration\n\n- [Calendly](https://calendly.com/) and [Cal.com](https://cal.com/) embedded support\n- Privacy-first with consent modal\n- Event scheduling capabilities\n\n## üìÇ File Structure\n\n```\nsrc/\n‚îú‚îÄ‚îÄ app/                # Next.js app router pages\n‚îú‚îÄ‚îÄ components/\n‚îÇ   ‚îú‚îÄ‚îÄ subatomic/     # Smallest reusable pieces\n‚îÇ   ‚îú‚îÄ‚îÄ atomic/        # Basic components\n‚îÇ   ‚îú‚îÄ‚îÄ molecular/     # Composite components\n‚îÇ   ‚îî‚îÄ‚îÄ organisms/     # Full sections\n‚îú‚îÄ‚îÄ contexts/          # React contexts\n‚îú‚îÄ‚îÄ services/          # Business logic\n‚îú‚îÄ‚îÄ lib/              # Core libraries\n‚îú‚îÄ‚îÄ utils/            # Utility functions\n‚îî‚îÄ‚îÄ types/            # TypeScript definitions\n```\n\n## üß™ Testing Commands\n\n```bash\n# Quick validation\ndocker compose exec scripthammer pnpm run test:quick\n\n# Full test suite\ndocker compose exec scripthammer pnpm run test:suite\n\n# Specific tests\ndocker compose exec scripthammer pnpm run type-check\ndocker compose exec scripthammer pnpm run lint\ndocker compose exec scripthammer pnpm run test:coverage\n```\n\n## üí° Why Scripthammer?\n\n1. **Quick Setup** - Create `.env`, run `docker compose up`, and you're developing\n2. **Reduced Configuration** - Opinionated choices with auto-detection from git\n3. **Production Features** - Battle-tested components and patterns\n4. **TypeScript First** - Comprehensive typing with strict mode enabled\n5. **Well Tested** - Full test suite with unit, E2E, and accessibility testing\n\n## üöÄ Getting Started (Docker Required)\n\n**‚ö†Ô∏è PREREQUISITE**: Docker and Docker Compose MUST be installed. This project does NOT support local development.\n\n```bash\n# Use the template on GitHub first\n# Then clone YOUR new repository\ngit clone https://github.com/YourUsername/your-new-repo.git\ncd your-new-repo\n\n# Create required .env file (MANDATORY)\ncp .env.example .env\n\n# Start Docker (ONLY way to run this project)\ndocker compose up  # First build takes 5-10 minutes\n\n# Open http://localhost:3000\n```\n\n**Remember**:\n\n- ‚úÖ `docker compose exec scripthammer pnpm install` - Correct\n- ‚ùå `pnpm install` - Will NOT work\n- ‚ùå `npm install` - Will NOT work\n\n## üéØ What's Next?\n\nCheck out the [CONSTITUTION.md](https://github.com/TortoiseWolfe/ScriptHammer/blob/main/.specify/memory/constitution.md) for the project principles and current sprint goals. Read [CLAUDE.md](https://github.com/TortoiseWolfe/ScriptHammer/blob/main/CLAUDE.md) for AI (Artificial Intelligence) pair programming guidelines and best practices when working with this codebase.\n\nThis is Scripthammer. Stop configuring, start shipping.\n",
      "excerpt": "Opinionated Next.js 15.5 template with PWA support, 32 DaisyUI themes, Docker-first development environment, and comprehensive testing suite.",
      "publishedAt": "2025-09-26T00:00:00.000Z",
      "updatedAt": "2025-10-08T01:20:15.179Z",
      "status": "published",
      "author": {
        "id": "default",
        "name": "TortoiseWolfe"
      },
      "metadata": {
        "tags": [
          "scripthammer",
          "next.js",
          "pwa",
          "typescript",
          "docker"
        ],
        "categories": [
          "documentation"
        ],
        "readingTime": 5,
        "wordCount": 923,
        "showToc": true,
        "showAuthor": true,
        "showShareButtons": true,
        "featured": false,
        "featuredImage": "/blog-images/scripthammer-intro/featured-og.svg",
        "featuredImageAlt": "Scripthammer - The Opinionated Next.js PWA Template with 32 themes and Docker development"
      },
      "seo": {
        "title": "Scripthammer - Opinionated Next.js PWA Template",
        "description": "Opinionated Next.js 15.5 template with PWA support, 32 DaisyUI themes, Docker-first development environment, and comprehensive testing suite.",
        "keywords": [
          "scripthammer",
          "next.js",
          "pwa",
          "typescript",
          "docker"
        ],
        "ogTitle": "Scripthammer - Opinionated Next.js PWA Template",
        "ogDescription": "Build production-ready Next.js apps with 32 themes, Docker development, PWA support, and comprehensive testing. No configuration hell.",
        "ogImage": "/blog-images/scripthammer-intro/featured-og.png",
        "twitterCard": "summary_large_image"
      },
      "frontMatter": {
        "title": "Scripthammer - Opinionated Next.js PWA Template",
        "author": "TortoiseWolfe",
        "date": "2025-09-26T00:00:00.000Z",
        "slug": "scripthammer-intro",
        "tags": [
          "scripthammer",
          "next.js",
          "pwa",
          "typescript",
          "docker"
        ],
        "categories": [
          "documentation"
        ],
        "excerpt": "Opinionated Next.js 15.5 template with PWA support, 32 DaisyUI themes, Docker-first development environment, and comprehensive testing suite.",
        "featuredImage": "/blog-images/scripthammer-intro/featured-og.svg",
        "featuredImageAlt": "Scripthammer - The Opinionated Next.js PWA Template with 32 themes and Docker development",
        "ogImage": "/blog-images/scripthammer-intro/featured-og.png",
        "ogTitle": "Scripthammer - Opinionated Next.js PWA Template",
        "ogDescription": "Build production-ready Next.js apps with 32 themes, Docker development, PWA support, and comprehensive testing. No configuration hell.",
        "twitterCard": "summary_large_image"
      }
    }
  ],
  "generated": "2025-10-08T14:57:17.785Z",
  "count": 6,
  "tags": [
    "payments",
    "stripe",
    "paypal",
    "supabase",
    "edge-functions",
    "offline-first",
    "gdpr",
    "authentication",
    "oauth",
    "security",
    "next.js",
    "typescript",
    "tutorial",
    "prp-workflow",
    "react",
    "component-development",
    "conversion-optimization",
    "business-strategy",
    "seo",
    "optimization",
    "content-writing",
    "best-practices",
    "web-development",
    "auto-config",
    "automation",
    "developer-experience",
    "scripthammer",
    "pwa",
    "docker"
  ],
  "categories": [
    "tutorials",
    "monetization",
    "security",
    "tutorial",
    "business",
    "DevOps",
    "Automation",
    "DX",
    "documentation"
  ]
}